{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.2.1.2 Predicting AdoptionSpeed (multiclass classification task)Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CN2 Rule Induction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![strutura.png](strutura.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stats_bench.png](stats_bench.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conf_matrix_bench.png](conf_matrix_bench.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file used is the *.csv* equivalent to the `df_processed_1_encoded` dataset.\n",
    "*Test and Score* parameters were set for 5-fold stratified cross-validation (the same as the cross-validation functions used in the remaining models).\n",
    "\n",
    "Similarly to all previous models, rule modelling displays poor overall performance across all classes being this more evident on the least representative classes `AdoptionSpeed`=0, `AdoptionSpeed`=1 and `AdoptionSpeed`=3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Benchmark conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Decision trees and K-Nearest Neighbours provided almost perfect results on the training sets but performed considerably worst on the test set. Both these models seem to be overfitting the training examples and failing to generalize over unseen examples. On the other hand, both Linear Support Vector Machines and Bernoulli Naive Bayes show considerable underfitting of the data with training scores below 0.40. \n",
    "\n",
    "Regarding individiual class performances none of the models showed great ability to provide the minority class (`AdoptionSpeed`=0) which underlines the need of oversampling the dataset to provide the algorithms with stronger evidence of that class. \n",
    "\n",
    "From all the tested approaches, the Bernoulli Naive Bayes model was the one that showcased better results in both AdoptionSpeed=1 and Linear Support Vector Machines the best for `AdoptionSpeed`=4 classes with higher precision and recall scores. On the other hand the K-Nearest Neighbours model performed better in both `AdoptionSpeed`=2 and `AdoptionSpeed`=3.\n",
    "\n",
    "All the models showcase similar low overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 Predicting Adoption Speed (Multiclass classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CN2 Rule Induction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![strutura.png](strutura.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stats.png](stats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conf_matrix.png](conf_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall performance of the model increased mainly due to the model's enhanced ability to correctly predict the most oversampled classes `AdoptionSpeed`=0, `AdoptionSpeed`=1 and `AdoptionSpeed`=3. The other two classes either decreased (`AdoptionSpeed`=4) our slightly increased predictive performance (`AdoptionSpeed`=2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Multi class classification - Conclusions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall predictive performance of the different models clearly improved on the most oversampled class, `AdoptionSpeed`=0. Despite this obvious improvement, that helped the overall performance of the models to increase, the former most dominant class `AdoptionSpeed`=4 had decreased performance across all models, when compared to the ones obtained on benchmark.\n",
    "\n",
    "Its fair to say that oversampling had great influence on the most oversampled classes and didn't help the formerly most dominant ones to improve.\n",
    "\n",
    "The most performative models were the Tree models, K-Nearest Neighbours and Rule models.\n",
    "\n",
    "The chosen linear models and probabilistic ones didn't show enough capacity to give adequate answers to the dataset even after oversampling and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
