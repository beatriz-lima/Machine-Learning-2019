{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import neighbors,tree, preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, recall_score, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "###### PRINT CONFUSION MATRIXES\n",
    "def confusion (y_true,y_predict,x):\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    y = np.unique(y_true)\n",
    "    f, ax = plt.subplots(figsize=(7, 5))\n",
    "    sns.heatmap(cm.T, cmap=\"coolwarm\", square=True, annot = True, fmt='d', cbar=False,\n",
    "                xticklabels=(y),\n",
    "                yticklabels=(y))\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label');\n",
    "    plt.title('Confusion Matrix - {} Set'.format(x))\n",
    "    \n",
    "    if len(y)==2:\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(\"True Negatives:{}\".format(tn))\n",
    "        print(\"False Positives:{}\".format(fp))\n",
    "        print(\"False Negatives:{}\".format(fn))\n",
    "        print(\"True Positives:{}\".format(tp))\n",
    "    else:\n",
    "        print(\"Not binary\")\n",
    "        \n",
    "    \n",
    "    \n",
    "#######################\n",
    "def set_dist (y,x):\n",
    "    print(\"{}\".format(x))\n",
    "    for i in np.unique(y):\n",
    "        print(\"{}: {}\".format(i,np.count_nonzero(y == i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PetFinder_dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading colour, breed and state labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_labels = pd.read_csv('color_labels.csv').set_index('ColorID')\n",
    "breed_labels = pd.read_csv('breed_labels.csv').set_index('BreedID')\n",
    "state_labels = pd.read_csv('state_labels.csv').set_index('StateID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How big is the dataset?\n",
    "The dataset contains 14993 entries with 24 features each.\n",
    "\n",
    "#### Is this the entire dataset?\n",
    "The original dataset from PetFinder.my contains over 150,000 animal profiles.\n",
    "\n",
    "#### Is this data representative enough?\n",
    "The dataset represents ~10% of the original data. EDA is required to best assess whether it can be considered a representative sample of the original population.\n",
    "\n",
    "#### Are there likely to be gross outliers or extraordinary sources of noise?\n",
    "EDA can shed light on this topic, by representing data distribution and irregularities that could point to errors in data.\n",
    "\n",
    "#### Are there any fields that are unique identifiers? These are the fields you might use for joining between datasets, etc.\n",
    "All animal profiles are uniquely identified by a PetID. Each PetID also has a non-unique RescuerID, and a non-unique State.\n",
    "\n",
    "#### Are the supposedly unique identifiers actually unique? What does it mean if they aren't?\n",
    "PetID.\n",
    "\n",
    "#### When data entries are blank, where does that come from?\n",
    "The only blank entries in this dataset correspond to animal profiles without an assigned name.\n",
    "\n",
    "#### How common are blank entries?\n",
    "There are ~1200 blank entries, which constitute a significant portion of the data. Given this number, and due to the fact that blank entries have meaning attributed to them, it would perhaps be best to keep this data in the dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand our dataset and to make decisions about feature selection, feature extraction and general cleaning of the data, we started by plotting distribution of the original features and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: *AdoptionSpeed*\n",
    "\n",
    "The target feature displayed a clear discrepancy in distribution, showing a significantly lower number of examples for AdoptionSpeed = 0. This imbalance should be addressed, as models tend to neglect minority classes if they don't have a large enough representation in the overall dataset, therefore compromising the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x=\"AdoptionSpeed\",data=df, kind='count')\n",
    "(ax.set_axis_labels(\"Adoption Speed\", \"Number of Pets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall correlations\n",
    "The plot bellow illustrates the absolute correlation between  each feature and the target class \"AdoptionSpeed\". All correlations are very low (<15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(exclude=['object'])\n",
    "corr_dict = {}\n",
    "for feature in numeric_df.columns:\n",
    "    corr_dict[feature] = abs(df['AdoptionSpeed'].corr(df[feature]))\n",
    "    #print(feature, '-->', corr_dict[feature])\n",
    "    \n",
    "corr_dict.pop('AdoptionSpeed')\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.bar(range(len(corr_dict)), list(corr_dict.values()), align='center')\n",
    "plt.xticks(range(len(corr_dict)), list(corr_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PetID\n",
    "\n",
    "Since PetID is not informative of the pet profile (it acts solely as a unique identifier of the page), it would be excluded from the analysis, although it will be used as an index for the dataFrame. It can be later useful when evaluating model performance, as the respective record values can reveal if certain features were appropriately categorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"PetID\", inplace=True) # change index to PetId\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "The following analysis was done to each feature:\n",
    "* Check the number of examples for each feature values.\n",
    "* Check the distribution of each feature values' among AdoptionSpeed classes.\n",
    "\n",
    "For the second step we used the following visualisation method, which returns not only a plot on the distribution but also a table of representativity percentage gain of each feature's values for each AdoptionSpeed class, relatively to AdoptionSpeed=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a stacked bar plot for any two categorical variables\n",
    "# also creates a relative frequency version of the same plot\n",
    "# and a relative gain compared to AdoptionSpeed=0 \n",
    "# frel=False to return only the absolute frequency plot\n",
    "\n",
    "def cat_distr_pairwise(cat_x,cat_y, df, frel):\n",
    "    \n",
    "    unique_cat_y = sorted(df[cat_y].unique())\n",
    "    unique_cat_x = sorted(df[cat_x].unique())\n",
    "    cat_count = pd.DataFrame(columns=unique_cat_y,index=unique_cat_x)\n",
    "    for y in unique_cat_y:\n",
    "        for x in unique_cat_x:\n",
    "            count = df[cat_y][(df[cat_x]==x) & (df[cat_y]==y)].count()\n",
    "            cat_count.at[x,y] = count \n",
    "    \n",
    "    def color(val):\n",
    "        if val < 0:\n",
    "            color = 'red'\n",
    "        elif val>0:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color='white'\n",
    "        return 'background-color: %s' % color\n",
    "    \n",
    "    if frel==False:\n",
    "        \n",
    "        #relative gain table\n",
    "        relgain = cat_count.pct_change().cumsum() * 100\n",
    "        print(\"Relative gain from AdoptionSpeed=0 (%):\")\n",
    "        display(relgain.style.applymap(color))\n",
    "        return cat_count.plot.bar(stacked=True, figsize=(10,7))\n",
    "    \n",
    "    else:\n",
    "        #relative frequency stacked bar plot\n",
    "        freq_cat_count = cat_count.divide(cat_count.sum(axis=1), axis=0)\n",
    "        \n",
    "        #relative gain table\n",
    "        relgain = freq_cat_count.pct_change().cumsum() * 100\n",
    "        print(\"Relative gain from AdoptionSpeed=0 (%):\")\n",
    "        display(relgain.style.applymap(color))\n",
    "\n",
    "        return freq_cat_count.plot.bar(stacked=True, figsize=(10,7), title=cat_y + \" relative distribution among AdoptionSpeed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now present the most important conclusions taken from this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type\n",
    "\n",
    "Because we are going to later create type-specific predictive models, it would be relevant to see the number of cases we have in our dataset for each animal (cat or dog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = sns.catplot(x=\"Type\",data=df, kind='count')\n",
    "(bx.set_axis_labels(\"Type\", \"Number of Pets\")\n",
    "    .set_xticklabels([\"Dogs\", \"Cats\"])\n",
    "    .set_titles(\"{col_name} {col_var}\")\n",
    "    .despine(left=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','Type', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, the number of examples of dogs and cats is fairly proportional, as well as their relative distribution among target classes. \n",
    "Looking at the gain table, it is clear that dogs(1) tend to get adopted later relatively to cats(2),  which we can see by the growing relative gain. In fact, the number of dogs with no adoption after 100 days (adoptionSpeed=4) is 37% higher than dogs being adopted on the same day (adoptionSpeed=0). On the other hand, we observe the opposite phenomena on cats. They tend to be adopted at ealier stages, being the number of cats with no adoption after 100 days (adoptionSpeed=4) is 29% lower than cats being adopted on the same day (adoptionSpeed=0).\n",
    "Despite this small discrepancies, we expect the resulting models' performance to be comparable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "Since a reasonable amount of the profiles didn't make any reference to name (empty) a first approach would be to fill those empty values with a fixed value such as \"No Name\" or similar.\n",
    "Other approach would be to transform this feature into a binary one with a 0 value for profiles with no name and a 1 value for the opposite.\n",
    "Since it was later found that some of the named profiles were filled with \"No Name\" and derivatives of this name such as \"No Name Yet\", \"V6\", \"å°è±¹çº¹\" etc., which are not proper names, we made an attempt to classify those cases as \"No name\" as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature - hasNames\n",
    "l = []\n",
    "ignore = []\n",
    "\n",
    "for i in df[\"Name\"]:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        l.append(0)\n",
    "    else:\n",
    "        if len(i)<3: #Consider that a 2 letter name is not a proper name.\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif re.search(\"[a-zA-Z]\", i) == None: #If name doesn't have letters, it's not a proper name.\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif re.search(\"unnamed|no name\",i, re.IGNORECASE) != None: \n",
    "            #If name string includes \"unnamed\" or \"no name\", it's not a proper name\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif len(i.split())>0:\n",
    "            l.append(1)\n",
    "\n",
    "print(\"A glimpse on the ignored names:\",ignore[:50])\n",
    "df_processed1 = df.copy()\n",
    "df_processed1.drop(\"Name\", axis=1, inplace = True)\n",
    "df_processed1.insert(1,\"hasName\",l) ##INSERT IN DATAFRAME\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.countplot(x=\"hasName\", data=df_processed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','hasName', df_processed1, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, the relative distribution of the \"noName\" feature values among \"AdoptionSpeed\" classes is very similar. This probabably means that the pet's name is not a very important factor in the adopter's decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "When looking at the Age distribution, we can see that there are peaks every 12 months. Young pets (less than 1 year old) are the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['Age'] # get Age array\n",
    "nr_bins = 1 + 3.322*math.log(len(a),2) # Number of bins according to Sturges rule\n",
    "sns.set(rc={'figure.figsize':(15,5)}) # set figure size\n",
    "\n",
    "# setting up the axis\n",
    "fig, ax = plt.subplots()\n",
    "ticks = [i for i in range(0,260,12)]\n",
    "ticks.pop(0)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xlim([0.0,250])\n",
    "\n",
    "sns.distplot(a, bins=round(nr_bins), kde=False, axlabel=\"Age (months)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cat is considered a kitten roughly until it reaches the age of 1 year old. The same goes for puppies. On the other hand, dogs and cats are considered Seniors roughly when they reach the age of 6 years. Of course, these are approximations, as the classification varies with the type of animal (cats or dogs), breed, size and many other factors.\n",
    "\n",
    "In this sense, we will consider these categories:\n",
    "* Baby - age 0-11 months => 0\n",
    "* Adult - age 12-71 months =>1\n",
    "* Senior - age 72-250 months =>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature - AgeGroup\n",
    "AgeGroup = []\n",
    "for i in df[\"Age\"]:\n",
    "    if i<12:\n",
    "        AgeGroup.append(0)\n",
    "    elif i<72:\n",
    "        AgeGroup.append(1)\n",
    "    else:\n",
    "        AgeGroup.append(2)\n",
    "\n",
    "df_processed2 = df_processed1.copy()\n",
    "df_processed2.drop(\"Age\", axis=1, inplace = True)\n",
    "df_processed2.insert(2,\"AgeGroup\",AgeGroup) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','AgeGroup', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative distribution of AgeGroups among AdoptionSpeed indicates that there seems to be no particular correlation between being younger and getting adopted earlier. Even without the dicretization we can observe the same phenomena: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.ylim(0, 260)\n",
    "sns.boxplot(data = df, x='AdoptionSpeed', y='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breed1 and Breed2\n",
    "\n",
    "According to the breeds feature labels, dogs breeds go from 1 to 240, plus 307, and cats breeds go from 241 to 306. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx1 = sns.catplot(x=\"Breed1\",data=df, kind='count',height=9, aspect=3)\n",
    "bx2 = sns.catplot(x=\"Breed2\",data=df, kind='count',height=9, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, and according to the breeds feature labels, we found some cats with dogs breeds assigned to them (15, 21, 25, 70, 114, 205, 218, 307).\n",
    "Therefore, and given the distribution of pets by breeds in which some breeds are poorly representated perhaps a good idea should be grouping pets by pure-race/mixed-race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature: Pure breed\n",
    "l3 =[]\n",
    "for i in range(len(df)):\n",
    "    if df['Breed1'][i]==307 or df['Breed2'][i]==307:\n",
    "        l3.append(0)\n",
    "    elif df['Breed1'][i]!=307 and df['Breed2'][i]==0:\n",
    "        l3.append(1)\n",
    "    elif df['Breed1'][i]==0 and df['Breed2'][i]!=307:\n",
    "        l3.append(1)\n",
    "    elif df['Breed1'][i]==df['Breed2'][i]:\n",
    "        l3.append(1)\n",
    "    else:\n",
    "        l3.append(0)\n",
    "        \n",
    "df_processed2.drop(\"Breed1\",axis=1,inplace=True)\n",
    "df_processed2.drop(\"Breed2\",axis=1,inplace=True) \n",
    "df_processed2.insert(3,'PureBreed',l3) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','PureBreed', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot and relative gain table we conclude that pure breed animals (1) tend to be adopted earlier, whereas mixed breed animals (0) are adopted later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color1, Color2 and Color3\n",
    "\n",
    "Each pet has at least one main color (color1) that according to the colors features label can go from black(1) to white(7). Pets can also have one or two additional colors (color2 and color3) with the same categorical values as the main color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zx1 = sns.catplot(x=\"Color1\",col=\"Type\",data=df, kind='count',height=4, aspect=0.8)\n",
    "#(zx1.set_axis_labels(\"Color 1\", \"Number of Pets\"))\n",
    "#zx2 = sns.catplot(x=\"Color2\",col=\"Type\",data=df, kind='count',height=4, aspect=0.8)\n",
    "#(zx2.set_axis_labels(\"Color 2\", \"Number of Pets\"))\n",
    "#zx3 = sns.catplot(x=\"Color3\",col=\"Type\",data=df, kind='count',height=4, aspect=0.8)\n",
    "#(zx3.set_axis_labels(\"Color 3\", \"Number of Pets\"))\n",
    "\n",
    "color1= cat_distr_pairwise('AdoptionSpeed','Color1', df, frel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color2 = cat_distr_pairwise('AdoptionSpeed','Color2', df, frel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color3 = cat_distr_pairwise('AdoptionSpeed','Color3', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of values for each color feature one of the following approaches should be appropriate to address the Color1, Color2 and Color3 features: \n",
    "* Group pets according to the number of colors one has. Pets with only one color will be assigned a \"SingleColor\" feature and so on;\n",
    "* Group colours according to their brightness/darkness.\n",
    "\n",
    "However we will leave further considerations on the feature engineering part later on this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantity\n",
    "\n",
    "Number of pets represented in profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = sns.catplot(x='Quantity', data=df, kind='count')\n",
    "(ax3.set_axis_labels(\"Quantity\", \"Number of Pets\"))\n",
    "print('There are {} profiles with a single pet'.format((list(df['Quantity'])).count(1)))\n",
    "print('There are {} profiles with multiple pets'.format(len(df['Quantity'])-list(list(df['Quantity'])).count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ste = cat_distr_pairwise('AdoptionSpeed','Quantity', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"inf\" values on the table indicate that there are no examples of a pet with AdoptionSpeed=0 for that feature instance. Therefore, all positive relative gains are 'infinite'.\n",
    "\n",
    "We can conclude that adds containing more than 5 pets could be more likely to be ignored, since those pets are adopted after a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fee\n",
    "\n",
    "After observing the fees distribution we considered 4 categories: \n",
    "* Free => 0\n",
    "* Tens => 1\n",
    "* Hundreds => 2\n",
    "* Thousands => 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in df[\"Fee\"]:\n",
    "    if i==0:\n",
    "        f.append(0)\n",
    "    elif i<100:\n",
    "        f.append(1)\n",
    "    elif i<1000:\n",
    "        f.append(2)\n",
    "    else:\n",
    "        f.append(3)\n",
    "\n",
    "df_processed2.drop(\"Fee\",axis=1,inplace=True) \n",
    "df_processed2.insert(4,'Free',f) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fee = cat_distr_pairwise('AdoptionSpeed','Free', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that pets with fees in the order of the thousands are less likely to be adopted fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RescuerID\n",
    "\n",
    "In order to extract some meaning from the 'RescuerID', we decided to create a new feature \"FrequentRescuer\" which indicates whether it is frequent for rescuers to save and advertise pets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(df['RescuerID'].unique())\n",
    "y = list(df['RescuerID'])\n",
    "z = []\n",
    "t = {}\n",
    "for i in x:\n",
    "    z.append(y.count(i))\n",
    "\n",
    "t['Rescuer'] = x\n",
    "t['entries'] = z\n",
    "\n",
    "e = pd.DataFrame(t)\n",
    "print('There are {} total rescuers in the dataset'.format(len(x)))\n",
    "print('There are {} rescuers with only 1 webpage entry in the dataset'.format(z.count(1)))\n",
    "print('There are {} rescuers with more than 1 webpage entry in the dataset'.format(len(x)-(z.count(1))))\n",
    "ax11 = sns.catplot(x='entries', data=e, kind='count', height=5, aspect=3)\n",
    "(ax11.set_axis_labels(\"Web page entries\", \"Number of Rescuers\")\n",
    "    .set_titles(\"{col_name} {col_var}\")\n",
    "    .despine(left=True))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset, the number of rescuers with a single entry in the MyPet webpage is greater than the number of rescuers who save and advertise more than 1 pet. This information could be useful on later anaylsis to discover whether the number of webpage profile entries associated with a rescuer has any interference in pet's apoption or adoption speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEW FEATURE FREQUENTRESCUER\n",
    "\n",
    "lista2 = []\n",
    "y = list(df['RescuerID'])\n",
    "for i in df['RescuerID']:\n",
    "      if y.count(i)>1:\n",
    "          lista2.append(float(1))\n",
    "      else:\n",
    "          lista2.append(float(0))\n",
    "          \n",
    "df_processed1.insert((df.columns.get_loc(\"RescuerID\"))+1,'FrequentRescuer',lista2) ##INSERT IN DATAFRAME\n",
    "df_processed1.drop(\"RescuerID\", axis=1)\n",
    "\n",
    "df_processed2.insert((df.columns.get_loc(\"RescuerID\"))+1,'FrequentRescuer',lista2) ##INSERT IN DATAFRAME\n",
    "df_processed2.drop(\"RescuerID\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VideoAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = sns.catplot(x='VideoAmt', data=df, kind='count')\n",
    "(ax2.set_axis_labels(\"Video Amount\", \"Number of Pets\"))\n",
    "print('There are {} profiles with 0 videos'.format((list(df['VideoAmt'])).count(0)))\n",
    "print('There are {} profiles with more than 0 videos'.format(len(df['VideoAmt'])-list(list(df['VideoAmt'])).count(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cat_distr_pairwise('AdoptionSpeed','VideoAmt', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photo Amt\n",
    "\n",
    "xxxxxxxxxxxx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.catplot(x='PhotoAmt', data=df, kind='count',height=4, aspect=3)\n",
    "(ax1.set_axis_labels(\"Photo Amount\", \"Number of Pets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pht = cat_distr_pairwise('AdoptionSpeed','PhotoAmt', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "In order to extract some meaning from the 'Description', we decided, as a first approach, to partition this continuous feature into discrete values.\n",
    "\n",
    "Since empty descriptions (size=0) probably have a direct influence in the adoption choice, it should be a category of its own. For that reason, we exclude empty descriptions from the discretization procces.\n",
    "\n",
    "We consider that the discretization of the 'description sizes' based on the quantiles strategy is appropriate, since it is plausible to say that the ad writers define what a 'medium' size description is. In that sense, a 'medium' sized description would have the average word count. In analogy, the smallest and largest descriptions would correspond to the first and third quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import statistics \n",
    "\n",
    "l=[]\n",
    "\n",
    "# List descriptions' lengths (i.e. number of char)\n",
    "for i in df['Description']:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        l.append(0)\n",
    "    else:\n",
    "        l.append(len(i.split()))\n",
    "\n",
    "mean = statistics.mean(l)\n",
    "print(\"The average descripton size:\" , mean)\n",
    "\n",
    "# Histogram\n",
    "a1 = np.asarray(l)\n",
    "nr_bins = 1 + 3.322*math.log(len(l),2) # Number of bins according to Sturges rule\n",
    "a1 = pd.Series(a1)\n",
    "a1.plot.hist(grid=True, bins = round(nr_bins), rwidth=0.9, color='#607c8e')\n",
    "plt.title('Description size distribution')\n",
    "plt.xlabel('Description size (# words)')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlim([0.0,1300])\n",
    "\n",
    "# Discretization by quantile strategy:\n",
    "a2 = np.asarray(l).reshape(-1,1) # Reshape data since we are working with just one feature\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3],encode='ordinal', strategy='quantile').fit(a2)\n",
    "decp = est.transform(a2)\n",
    "\n",
    "print(\"According to this discretization, the bin edges should be:\")\n",
    "print(est.bin_edges_) # how the data is distributed in the four bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, we present a new feature 'DescriptionSize' whose possible values include:\n",
    "* 'Empty' for descriptions containing 0 words => 0\n",
    "* 'Small' for descriptions containing 1-28 words => 1\n",
    "* 'Medium' for descriptions containing 29-65 words => 2\n",
    "* 'Large' for descriptions containing 66-1257 words => 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new feature 'Description size'\n",
    "d = []\n",
    "\n",
    "for i in df['Description']:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        d.append(0)\n",
    "    else:\n",
    "        a= len(i.split())\n",
    "        if a<29:\n",
    "            d.append(1)\n",
    "        elif a<66:\n",
    "            d.append(2)\n",
    "        else:\n",
    "            d.append(3)\n",
    "         \n",
    "df_processed1.drop(\"Description\", axis=1)\n",
    "df_processed1.insert(6,\"DescriptionSize\",l) ##INSERT IN DATAFRAME\n",
    "\n",
    "df_processed2.drop(\"Description\", axis=1)\n",
    "df_processed2.insert(6,\"DescriptionSize\",d) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other conclusions\n",
    "* Pets with maturity size 'Small' (1) and 'Extra Large'(4) are less likely to be in the adoption centre for a very long time (-45.0552% and -97.3772 of pets at AdoptionSpeed=4 relatively to AdoptionSpeed=1, respectively). \n",
    "* Pets with long fur(3) very rarely stay at the adoption centre for a long time (-116.814% of pets at AdoptionSpeed=4 relatively to AdoptionSpeed=1).\n",
    "* Sterilized pets tend to be adopted later (+82.13% of pets at AdoptionSpeed=4 relatively to AdoptionSpeed=1).\n",
    "* Pets with serious injuries (Health=3) are very more likely to be adopted after a long time, or not adopted at all (+182.091% of pets at AdoptionSpeed=4 relatively to AdoptionSpeed=1). \n",
    "* No pets were adopted in the same day having the add not provide a description!\n",
    "* There was no clear evidence that the distribution of the features values among AdoptionSpeed classes was biased for features Gender, Vaccinated, Dewormed, States, FrequentRescuer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Supervised Learning) - Predicting Adoption and Adoption Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our EDA we already preprocessed some of the features, for data visualization purposes. The result are two datasets:\n",
    "* **df_processed1**: which we will use to benchmark the models' performance without the discretization of features discussed earlier, since they can remove the fine grain information that might be beneficial to the learning proccess. Some data cleaning was done, namely in features PetID, Name, RescuerID and DescriptionSize (in words, instead of text Description).\n",
    "\n",
    "* **df_processed2**: which is the data set with the derived features and data cleaning. We will see if the dicretization will be helpful for the models or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imbalancement\n",
    "XXXXXX\n",
    "-- use df_processed2 for this. df_processed1 is just for benchmarking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification - Random Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_balanced = df_processed2.copy()\n",
    "df_processed2_b_balanced = df_processed2_b_balanced.rename(columns={'AdoptionSpeed': 'Adoption'})\n",
    "df_processed2_b_balanced = df_processed2_b_balanced.replace({'Adoption':[0,2,3]},1)\n",
    "df_processed2_b_balanced = df_processed2_b_balanced.replace({'Adoption':4},0)    \n",
    "\n",
    "set_dist(df_processed2_b_balanced,'Distribution of pets for each Adoption category before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_balanced_ROA = df_processed2_b_balanced.copy()\n",
    "ros_b = RandomOverSampler(sampling_strategy='minority',random_state=42)\n",
    "X_ros_b, y_ros_b = ros_b.fit_resample(df_processed2_b_balanced_ROA.iloc[:,:-1], df_processed2_b_balanced_ROA['Adoption'])\n",
    "\n",
    "df_processed2_b_balanced_ROA = X_ros_b.join(y_ros_b)\n",
    "\n",
    "set_dist(df_processed2_b_balanced_ROA,'Distribution of pets for each Adoption category after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass classification - Random Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_balanced = df_processed2.copy()\n",
    "\n",
    "set_dist(df_processed2_m_balanced,'Distribution of pets by Adoption Speed before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_balanced_ROA = df_processed2_m_balanced.copy()\n",
    "ros_m = RandomOverSampler(random_state=42)\n",
    "X_ros_m, y_ros_m = ros_m.fit_resample(df_processed2_m_balanced_ROA.iloc[:,:-1], df_processed2_m_balanced_ROA['AdoptionSpeed'])\n",
    "\n",
    "df_processed2_m_balanced_ROA = X_ros_m.join(y_ros_m)\n",
    "\n",
    "set_dist(df_processed2_m_balanced_ROA,'Distribution of pets by Adoption Speed after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dogs - Random Over-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_dog = df_processed2_b_balanced.copy()\n",
    "\n",
    "df_processed2_b_dog = df_processed2_b_dog[df_processed2_b_dog['Type']==1]\n",
    "\n",
    "set_dist(df_processed2_b_dog,'Distribution of Dogs for each Adoption category before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_dogs_ROA = df_processed2_b_dog.copy()\n",
    "ros_b_dogs = RandomOverSampler(sampling_strategy='minority',random_state=42)\n",
    "X_ros_b_dogs, y_ros_b_dogs = ros_b_dogs.fit_resample(df_processed2_b_dogs_ROA.iloc[:,:-1], df_processed2_b_dogs_ROA['Adoption'])\n",
    "\n",
    "df_processed2_b_dogs_ROA = X_ros_b_dogs.join(y_ros_b_dogs)\n",
    "\n",
    "set_dist(df_processed2_b_dogs_ROA,'Distribution of Dogs for each Adoption category after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_dogs = df_processed2_m_balanced.copy()\n",
    "df_processed2_m_dogs = df_processed2_m_dogs[df_processed2_m_dogs['Type']==1]\n",
    "\n",
    "set_dist(df_processed2_m_dogs,'Adoption Speed distribution for dogs before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_dogs_ROA = df_processed2_m_dogs.copy()\n",
    "\n",
    "ros_m_dogs = RandomOverSampler(random_state=42)\n",
    "X_ros_m_dogs, y_ros_m_dogs = ros_m_dogs.fit_resample(df_processed2_m_dogs_ROA.iloc[:,:-1], df_processed2_m_dogs_ROA['AdoptionSpeed'])\n",
    "\n",
    "df_processed2_m_dogs_ROA = X_ros_m_dogs.join(y_ros_m_dogs)\n",
    "set_dist(df_processed2_m_dogs_ROA,'Adoption Speed distribution for dogs after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cats - Random Over-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_cats = df_processed2_b_balanced.copy()\n",
    "\n",
    "df_processed2_b_cats = df_processed2_b_cats[df_processed2_b_cats['Type']==2]\n",
    "\n",
    "set_dist(df_processed2_b_cats,'Distribution of cats for each Adoption category before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_b_cats_ROA = df_processed2_b_cats.copy()\n",
    "\n",
    "ros_b_cats = RandomOverSampler(sampling_strategy='minority',random_state=42)\n",
    "X_ros_b_cats, y_ros_b_cats = ros_b_cats.fit_resample(df_processed2_b_cats_ROA.iloc[:,:-1], df_processed2_b_cats_ROA['Adoption'])\n",
    "df_processed2_b_cats_ROA = X_ros_b_cats.join(y_ros_b_cats)\n",
    "\n",
    "set_dist(df_processed2_b_cats_ROA,'Distribution of cats for each Adoption category after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_cats = df_processed2_m_balanced.copy()\n",
    "df_processed2_m_cats = df_processed2_m_cats[df_processed2_m_cats['Type']==2]\n",
    "\n",
    "set_dist(df_processed2_m_cats,'Adoption Speed distribution for cats before Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed2_m_cats_ROA = df_processed2_m_cats.copy()\n",
    "\n",
    "ros_m_cats = RandomOverSampler(random_state=42)\n",
    "X_ros_m_cats, y_ros_m_cats = ros_m_cats.fit_resample(df_processed2_m_cats_ROA.iloc[:,:-1], df_processed2_m_cats_ROA['AdoptionSpeed'])\n",
    "df_processed2_m_cats_ROA = X_ros_m_cats.join(y_ros_m_cats)\n",
    "\n",
    "set_dist(df_processed2_m_cats_ROA,'Adoption Speed distribution for cats after Random Over-Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Learning Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEATURE ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING THE FOLLOWING FEATURES\n",
    "## 'Type','Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'\n",
    "encoder = OneHotEncoder()\n",
    "df_encoded = encoder.fit_transform(df_processed1[['Type','Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State']]).toarray()\n",
    "column_name = encoder.get_feature_names(['Type','Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'])\n",
    "df_processed1_encoded =  pd.DataFrame(df_encoded, columns= column_name)\n",
    "\n",
    "print(column_name) #encoded features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT THE NON ENCODED FEATURES IN THE DATAFRAME AGAIN\n",
    "df_processed1_encoded.insert(2,'hasName',df_processed1['hasName']) ## hasName  \n",
    "df_processed1_encoded.insert(3,'Age',df_processed1['Age']) ## AGE  \n",
    "df_processed1_encoded.insert(4,'DescriptionSize',df_processed1['DescriptionSize']) ## DescriptionSize  \n",
    "df_processed1_encoded.insert(5,'Quantity',df_processed1['Quantity']) ## QUANTITY    \n",
    "df_processed1_encoded.insert(6,'Fee',df_processed1['Fee']) ## FEE  \n",
    "df_processed1_encoded.insert(7,'FrequentRescuer',df_processed1['FrequentRescuer']) ## FrequentRescuer  \n",
    "df_processed1_encoded.insert(8,'VideoAmt',df_processed1['VideoAmt']) ## VideoAmt  \n",
    "df_processed1_encoded.insert(9,'PhotoAmt',df_processed1['PhotoAmt']) ## PhotoAmt\n",
    "df_processed1_encoded.insert((len(df_processed1_encoded.columns)),'AdoptionSpeed',df_processed1['AdoptionSpeed']) ## AdoptionSpeed\n",
    "\n",
    "print(df_processed1_encoded.columns.values) ## data frame for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = df_processed1_encoded.shape[1]\n",
    "matrix = df_processed1_encoded.values # Convert dataframe to darray\n",
    "examples = matrix [:, 0:nc-1] # get features \n",
    "target = matrix [:, nc-1] # get class (last columns)           \n",
    "fnames = df_processed1_encoded.columns.values[0:nc-1] #get features names\n",
    "tname = df_processed1_encoded.columns.values[nc-1] #get target name\n",
    "\n",
    "examples = examples.astype(float)\n",
    "target = target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data frame into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(examples, target, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Adoption (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary task, the adoptionspeed had to be converted into a binary feature (0 - for profiles with adoptionspeed = 4; 1 for profiles with adoptionspeed < 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = y_train.copy()\n",
    "y_test_binary = y_test.copy()\n",
    "\n",
    "for i in range(len(y_train_binary)):\n",
    "    if y_train_binary[i]<4:\n",
    "        y_train_binary[i]=1\n",
    "    else:\n",
    "        y_train_binary[i]=0\n",
    "\n",
    "for i in range(len(y_test_binary)):\n",
    "    if y_test_binary[i]<4:\n",
    "        y_test_binary[i]=1\n",
    "    else:\n",
    "        y_test_binary[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the train set is: {}\".format(np.count_nonzero(y_train_binary == 1)))\n",
    "print(\"Number of negative cases in the train set is: {}\".format(np.count_nonzero(y_train_binary == 0)))\n",
    "print(\"Ratio positive to negative cases in the training set: {}\".format((np.count_nonzero(y_train_binary == 1))/(np.count_nonzero(y_train_binary == 0))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_b = neighbors.KNeighborsClassifier(n_neighbors=3) ## 3 neighbors for starters\n",
    "knn_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_b = knn_b.fit(X_train, y_train_binary)\n",
    "\n",
    "print(\"Accuracy on training set:\",  knn_b.score(X_train, y_train_binary))\n",
    "\n",
    "print(\"Accuracy on test set:\",  knn_b.score(X_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_b_knn = knn_b.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train_binary,y_train_pred_b_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_b_knn = knn_b.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary,y_test_pred_b_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train_binary,y_train_pred_b_knn,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test_binary,y_test_pred_b_knn,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_b = GaussianNB()\n",
    "gnb_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NAIVE BAYES ON THE TRAIN SET\n",
    "gnb_b = gnb_b.fit(X_train, y_train_binary)\n",
    "\n",
    "print(\"Accuracy on training set:\",  gnb_b.score(X_train, y_train_binary))\n",
    "\n",
    "print(\"Accuracy on test set:\",  gnb_b.score(X_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for train set\n",
    "y_train_pred_b_GNB = gnb_b.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train_binary,y_train_pred_b_GNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for test set\n",
    "y_test_pred_b_GNB = gnb_b.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary,y_test_pred_b_GNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train_binary,y_train_pred_b_GNB,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test_binary,y_test_pred_b_GNB,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_trees_b = tree.DecisionTreeClassifier() # criterion = \"Gini\"\n",
    "\n",
    "dec_trees_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_trees_b = dec_trees_b.fit(X_train, y_train_binary)\n",
    "\n",
    "print(\"Accuracy on training set:\",  dec_trees_b.score(X_train, y_train_binary))\n",
    "\n",
    "print(\"Accuracy on test set:\",  dec_trees_b.score(X_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for train set\n",
    "y_train_pred_b_trees = dec_trees_b.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train_binary,y_train_pred_b_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_b_trees = dec_trees_b.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary,y_test_pred_b_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train_binary,y_train_pred_b_trees,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test_binary,y_test_pred_b_trees,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. LINEAR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A ESCOLHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Predicting AdoptionSpeed (Multiclass classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist(y_train,'Adoption Speed - Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist(y_train,'Adoption Speed - Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_m = neighbors.KNeighborsClassifier(n_neighbors=3) ## 3 neighbors for starters\n",
    "knn_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_m = knn_m.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set:\",  knn_m.score(X_train, y_train))\n",
    "print(\"Accuracy on test set:\",  knn_m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_m_KNN = knn_m.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_train_pred_m_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_m_KNN = knn_m.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_test_pred_m_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train,y_train_pred_m_KNN,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test,y_test_pred_m_KNN,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_m = GaussianNB()\n",
    "gnb_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NAIVE BAYES ON THE TRAIN SET\n",
    "gnb_m = gnb_m.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set:\",  gnb_m.score(X_train, y_train))\n",
    "print(\"Accuracy on test set:\",  gnb_m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for train set\n",
    "y_train_pred_m_GBN = gnb_m.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_train_pred_m_GBN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for test set\n",
    "y_test_pred_m_GBB = gnb_m.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_test_pred_m_GBB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train,y_train_pred_m_GBN,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test,y_test_pred_m_GBB,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_trees_m = tree.DecisionTreeClassifier() # criterion = \"Gini\"\n",
    "\n",
    "dec_trees_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_trees_m = dec_trees_m.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set:\",  dec_trees_m.score(X_train, y_train))\n",
    "print(\"Accuracy on test set:\",  dec_trees_m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for train set\n",
    "y_train_pred_m_trees = dec_trees_m.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_train_pred_m_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_m_trees = dec_trees_m.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_test_pred_m_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_train,y_train_pred_m_trees,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion (y_test,y_test_pred_m_trees,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATS (type 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed1_cats = df_processed1.copy()\n",
    "\n",
    "df_processed1_cats = df_processed1_cats[df_processed1_cats['Type']==2]\n",
    "\n",
    "print(df_processed1_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING THE FOLLOWING FEATURES\n",
    "## 'Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'\n",
    "encoder_cats = OneHotEncoder()\n",
    "df_encoded_cats = encoder_cats.fit_transform(df_processed1_cats[['Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State']]).toarray()\n",
    "column_name_cats = encoder_cats.get_feature_names(['Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'])\n",
    "df_processed1_cats_encoded =  pd.DataFrame(df_encoded_cats, columns= column_name_cats)\n",
    "\n",
    "print(column_name_cats) #encoded features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT THE NON ENCODED FEATURES IN THE DATAFRAME AGAIN\n",
    "df_processed1_cats_encoded.insert(2,'hasName',df_processed1_cats['hasName']) ## hasName  \n",
    "df_processed1_cats_encoded.insert(3,'Age',df_processed1_cats['Age']) ## AGE  \n",
    "df_processed1_cats_encoded.insert(4,'DescriptionSize',df_processed1_cats['DescriptionSize']) ## DescriptionSize  \n",
    "df_processed1_cats_encoded.insert(5,'Quantity',df_processed1_cats['Quantity']) ## QUANTITY    \n",
    "df_processed1_cats_encoded.insert(6,'Fee',df_processed1_cats['Fee']) ## FEE  \n",
    "df_processed1_cats_encoded.insert(7,'FrequentRescuer',df_processed1_cats['FrequentRescuer']) ## FrequentRescuer  \n",
    "df_processed1_cats_encoded.insert(8,'VideoAmt',df_processed1_cats['VideoAmt']) ## VideoAmt  \n",
    "df_processed1_cats_encoded.insert(9,'PhotoAmt',df_processed1_cats['PhotoAmt']) ## PhotoAmt\n",
    "df_processed1_cats_encoded.insert((len(df_processed1_cats_encoded.columns)),'AdoptionSpeed',df_processed1_cats['AdoptionSpeed']) ## AdoptionSpeed\n",
    "\n",
    "print(df_processed1_cats_encoded.columns.values) ## data frame for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Predicting Adoption (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Predicting Adoption Speed (Multiclass classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOGS (Type 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed1_dogs = df_processed1.copy()\n",
    "\n",
    "df_processed1_dogs = df_processed1_dogs[df_processed1_dogs['Type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING THE FOLLOWING FEATURES\n",
    "## 'Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'\n",
    "encoder_dogs = OneHotEncoder()\n",
    "df_encoded_dogs = encoder_dogs.fit_transform(df_processed1_dogs[['Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State']]).toarray()\n",
    "column_name_dogs = encoder_dogs.get_feature_names(['Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State'])\n",
    "df_processed1_dogs_encoded =  pd.DataFrame(df_encoded_dogs, columns= column_name_dogs)\n",
    "\n",
    "print(column_name_dogs) #encoded features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT THE NON ENCODED FEATURES IN THE DATAFRAME AGAIN\n",
    "df_processed1_dogs_encoded.insert(2,'hasName',df_processed1_dogs['hasName']) ## hasName  \n",
    "df_processed1_dogs_encoded.insert(3,'Age',df_processed1_dogs['Age']) ## AGE  \n",
    "df_processed1_dogs_encoded.insert(4,'DescriptionSize',df_processed1_dogs['DescriptionSize']) ## DescriptionSize  \n",
    "df_processed1_dogs_encoded.insert(5,'Quantity',df_processed1_dogs['Quantity']) ## QUANTITY    \n",
    "df_processed1_dogs_encoded.insert(6,'Fee',df_processed1_dogs['Fee']) ## FEE  \n",
    "df_processed1_dogs_encoded.insert(7,'FrequentRescuer',df_processed1_dogs['FrequentRescuer']) ## FrequentRescuer  \n",
    "df_processed1_dogs_encoded.insert(8,'VideoAmt',df_processed1_dogs['VideoAmt']) ## VideoAmt  \n",
    "df_processed1_dogs_encoded.insert(9,'PhotoAmt',df_processed1_dogs['PhotoAmt']) ## PhotoAmt\n",
    "df_processed1_dogs_encoded.insert((len(df_processed1_dogs_encoded.columns)),'AdoptionSpeed',df_processed1_dogs['AdoptionSpeed']) ## AdoptionSpeed\n",
    "\n",
    "print(df_processed1_dogs_encoded.columns.values) ## data frame for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Predicting Adoption (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Predicting Adoption Speed (Multiclass classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Data balancement ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (Unsupervised Learning) - Charactering Adopted Pets and Adoption Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize pets that were actually adopted and their adoption speed**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Adoption/AdoptionSpeed**.\n",
    "* **Clustering algorithms to find similar groups of pets**. Is it possible to find groups of pets with the same/similar adoption speed.\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preprocessing Data for Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Finding Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Preprocessing Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
