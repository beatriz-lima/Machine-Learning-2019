{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project  - Learning about Pet Adoption using PetFinder.my Dataset\n",
    "\n",
    "Beatriz Lima 49377, David Almeida 54120, Tiago Pereira 49174\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0 (Know your Data) - Exploratory Data Analysis\n",
    "  * 0.1. Loading Data\n",
    "  * 0.2. Understanding Data\n",
    "    + Basic Questions\n",
    "    + Exploratory Data Analysis\n",
    "\n",
    "#### Task 1 (Supervised Learning) - Predicting Adoption and Adoption Speed\n",
    "  * 1.1. Preprocessing Data for Classification\n",
    "    + Features impact\n",
    "    + Data imbalance\n",
    "    + Feature Encoding\n",
    "    \n",
    "    \n",
    "  * 1.2. Learning Classifiers\n",
    "    + 1.2.1 Benchmark\n",
    "        - 1.2.1.1 Predicting Adoption (binary classification task)\n",
    "        - 1.2.1.2 Predicting AdoptionSpeed (multiclass classification task) \n",
    "    + 1.2.2 Predicting Adoption (binary classification task)\n",
    "    + 1.2.3 Predicting Adoption Speed (Multiclass classification task)\n",
    "    + 1.2.4 Predicting Adoption/Adoption Speed for dogs\n",
    "        - 1.2.4.1 Binary Classification\n",
    "        - 1.2.4.2 Multiclass Classficiation\n",
    "    + 1.2.5 Predicting Adoption/Adoption Speed for cats\n",
    "        - 1.2.5.1 Binary Classification\n",
    "        - 1.2.5.2 Multiclass Classficiation\n",
    "   \n",
    "   * 1.3. Classification - Results and Discussion \n",
    "   \n",
    "#### Task 2 (Unsupervised Learning) - Charactering Adopted Pets and Adoption Speed\n",
    "\n",
    "   * Associoation Rule Mining:\n",
    "   \n",
    "       + 2.1. Preprocessing Data for Association Rule Mining\n",
    "       + 2.2. Finding Associations\n",
    "           + Binary Classification\n",
    "           + Multiclass Classficiation\n",
    "       + 2.3 Association Rules - Results and Discussion\n",
    "   \n",
    "   * Clustering:\n",
    "      + 2.4. Preprocessing Data for Clustering\n",
    "      + 2.5. Finding Groups\n",
    "          - Binary Analysis\n",
    "          - Multiclass Analysis\n",
    "      + 2.6. Clustering - Results and Discussion\n",
    "    \n",
    "#### Task 3 - Final Comments and Conclusions\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import neighbors,tree, preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, recall_score, accuracy_score\n",
    "import sklearn.naive_bayes\n",
    "#from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB ,CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14993 entries, 0 to 14992\n",
      "Data columns (total 24 columns):\n",
      "Type             14993 non-null int64\n",
      "Name             13736 non-null object\n",
      "Age              14993 non-null int64\n",
      "Breed1           14993 non-null int64\n",
      "Breed2           14993 non-null int64\n",
      "Gender           14993 non-null int64\n",
      "Color1           14993 non-null int64\n",
      "Color2           14993 non-null int64\n",
      "Color3           14993 non-null int64\n",
      "MaturitySize     14993 non-null int64\n",
      "FurLength        14993 non-null int64\n",
      "Vaccinated       14993 non-null int64\n",
      "Dewormed         14993 non-null int64\n",
      "Sterilized       14993 non-null int64\n",
      "Health           14993 non-null int64\n",
      "Quantity         14993 non-null int64\n",
      "Fee              14993 non-null int64\n",
      "State            14993 non-null int64\n",
      "RescuerID        14993 non-null object\n",
      "VideoAmt         14993 non-null int64\n",
      "Description      14981 non-null object\n",
      "PetID            14993 non-null object\n",
      "PhotoAmt         14993 non-null float64\n",
      "AdoptionSpeed    14993 non-null int64\n",
      "dtypes: float64(1), int64(19), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('PetFinder_dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading colour, breed and state labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_labels = pd.read_csv('color_labels.csv').set_index('ColorID')\n",
    "breed_labels = pd.read_csv('breed_labels.csv').set_index('BreedID')\n",
    "state_labels = pd.read_csv('state_labels.csv').set_index('StateID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How big is the dataset?\n",
    "The dataset contains 14993 entries with 24 features each.\n",
    "\n",
    "#### Is this the entire dataset?\n",
    "The original dataset from PetFinder.my contains over 150,000 animal profiles.\n",
    "\n",
    "#### Is this data representative enough?\n",
    "The dataset represents ~10% of the original data. EDA is required to best assess whether it can be considered a representative sample of the original population.\n",
    "\n",
    "#### Are there likely to be gross outliers or extraordinary sources of noise?\n",
    "EDA can shed light on this topic, by representing data distribution and irregularities that could point to errors in data.\n",
    "\n",
    "#### Are there any fields that are unique identifiers? These are the fields you might use for joining between datasets, etc.\n",
    "All animal profiles are uniquely identified by a PetID. Each PetID also has a non-unique RescuerID, and a non-unique State.\n",
    "\n",
    "#### When data entries are blank, where does that come from?\n",
    "Some animal profiles have no assigned name. There are also some features which have a default value set for cases in which that feature is not specified or applicable to the data entry.\n",
    "\n",
    "#### How common are blank entries?\n",
    "There are ~1200 blank name entries, which constitute a significant portion of the data. It would perhaps be best to keep this data in the dataset for analysis. Other features with default value entries should also be kept, because, like a profile without a name, unspecified animal characteristics have a meaning relevant to our objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand our dataset and to make decisions about feature selection, feature extraction and general cleaning of the data, we started by plotting distribution of the original features and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: *AdoptionSpeed*\n",
    "\n",
    "The target feature displayed a clear discrepancy in distribution, showing a significantly lower number of examples for `AdoptionSpeed = 0`. This imbalance should be addressed, as models tend to neglect minority classes if they don't have a large enough representation in the overall dataset, therefore compromising the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x=\"AdoptionSpeed\",data=df, kind='count')\n",
    "(ax.set_axis_labels(\"Adoption Speed\", \"Number of Pets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall correlations\n",
    "The plot bellow illustrates the absolute correlation between  each feature and the target class `AdoptionSpeed`. All correlations are very low (<15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(exclude=['object'])\n",
    "corr_dict = {}\n",
    "for feature in numeric_df.columns:\n",
    "    corr_dict[feature] = abs(df['AdoptionSpeed'].corr(df[feature]))\n",
    "    #print(feature, '-->', corr_dict[feature])\n",
    "    \n",
    "corr_dict.pop('AdoptionSpeed')\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.bar(range(len(corr_dict)), list(corr_dict.values()), align='center')\n",
    "plt.xticks(range(len(corr_dict)), list(corr_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PetID\n",
    "\n",
    "Since PetID is not informative of the pet profile (it acts solely as a unique identifier of the page), it would be excluded from the analysis, although it will be used as an index for the dataFrame. It can be later useful when evaluating model performance, as the respective record values can reveal if certain features were appropriately categorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3422e4906</td>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850a43f90</td>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  \\\n",
       "PetID                                                                       \n",
       "86e1089a3     2       Nibble    3     299       0       1       1       7   \n",
       "6296e909a     2  No Name Yet    1     265       0       1       1       2   \n",
       "3422e4906     1       Brisco    1     307       0       1       2       7   \n",
       "5842f1ff5     1         Miko    4     307       0       2       1       2   \n",
       "850a43f90     1       Hunter    1     307       0       1       1       0   \n",
       "\n",
       "           Color3  MaturitySize  ...  Sterilized  Health  Quantity  Fee  \\\n",
       "PetID                            ...                                      \n",
       "86e1089a3       0             1  ...           2       1         1  100   \n",
       "6296e909a       0             2  ...           3       1         1    0   \n",
       "3422e4906       0             2  ...           2       1         1    0   \n",
       "5842f1ff5       0             2  ...           2       1         1  150   \n",
       "850a43f90       0             2  ...           2       1         1    0   \n",
       "\n",
       "           State                         RescuerID  VideoAmt  \\\n",
       "PetID                                                          \n",
       "86e1089a3  41326  8480853f516546f6cf33aa88cd76c379         0   \n",
       "6296e909a  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "3422e4906  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "5842f1ff5  41401  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "850a43f90  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "\n",
       "                                                 Description PhotoAmt  \\\n",
       "PetID                                                                   \n",
       "86e1089a3  Nibble is a 3+ month old ball of cuteness. He ...      1.0   \n",
       "6296e909a  I just found it alone yesterday near my apartm...      2.0   \n",
       "3422e4906  Their pregnant mother was dumped by her irresp...      7.0   \n",
       "5842f1ff5  Good guard dog, very alert, active, obedience ...      8.0   \n",
       "850a43f90  This handsome yet cute boy is up for adoption....      3.0   \n",
       "\n",
       "           AdoptionSpeed  \n",
       "PetID                     \n",
       "86e1089a3              2  \n",
       "6296e909a              0  \n",
       "3422e4906              3  \n",
       "5842f1ff5              2  \n",
       "850a43f90              2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"PetID\", inplace=True) # change index to PetId\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "The following analysis was done to each feature:\n",
    "* Check the number of examples for each feature values.\n",
    "* Check the distribution of each feature values' among AdoptionSpeed classes.\n",
    "\n",
    "For the second step we used the following visualisation method, which returns not only a plot on the distribution but also a table of representativity percentage gain of each feature's values for each `AdoptionSpeed` class, relative to `AdoptionSpeed = 0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a stacked bar plot for any two categorical variables\n",
    "# also creates a relative frequency version of the same plot\n",
    "# and a relative gain compared to AdoptionSpeed=0 \n",
    "# frel=False to return only the absolute frequency plot\n",
    "\n",
    "def cat_distr_pairwise(cat_x,cat_y, df, frel):\n",
    "    \n",
    "    unique_cat_y = sorted(df[cat_y].unique()) #ordered list of categories in variable y\n",
    "    unique_cat_x = sorted(df[cat_x].unique()) #ordered list of categories in variable x\n",
    "    cat_count = pd.DataFrame(columns=unique_cat_y,index=unique_cat_x) #DataFrame of x categories by y categories\n",
    "    for y in unique_cat_y: #count each type of y category...\n",
    "        for x in unique_cat_x: #... for each type of x category (e.g.: all dogs' adoption speed, then all cats' adoption speed)\n",
    "            count = df[cat_y][(df[cat_x]==x) & (df[cat_y]==y)].count() \n",
    "            cat_count.at[x,y] = count \n",
    "    \n",
    "    def color(val):\n",
    "        if val < 0:\n",
    "            color = 'red'\n",
    "        elif val>0:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color='white'\n",
    "        return 'background-color: %s' % color\n",
    "    \n",
    "    if frel==False:\n",
    "        \n",
    "        #relative gain table\n",
    "        relgain = cat_count.pct_change().cumsum() * 100\n",
    "        print(\"Relative gain from AdoptionSpeed=0 (%):\")\n",
    "        display(relgain.style.applymap(color))\n",
    "        # alternative: display(relgain.style.bar(align='zero', color=['#d65f5f', '#5fba7d'])\n",
    "        return cat_count.plot.bar(stacked=True, figsize=(10,7))\n",
    "    \n",
    "    else:\n",
    "        #relative frequency stacked bar plot\n",
    "        freq_cat_count = cat_count.divide(cat_count.sum(axis=1), axis=0)\n",
    "        \n",
    "        #relative gain table\n",
    "        relgain = freq_cat_count.pct_change().cumsum() * 100\n",
    "        print(\"Relative gain from AdoptionSpeed=0 (%):\")\n",
    "        display(relgain.style.applymap(color))\n",
    "        # alternative: display(relgain.style.bar(align='zero', color=['#d65f5f', '#5fba7d'])\n",
    "\n",
    "        return freq_cat_count.plot.bar(stacked=True, figsize=(10,7), title=cat_y + \" relative distribution among AdoptionSpeed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now present the most important conclusions taken from this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type\n",
    "\n",
    "Because we are going to later create type-specific predictive models, it would be relevant to see the number of cases we have in our dataset for each animal (cat or dog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = sns.catplot(x=\"Type\",data=df, kind='count')\n",
    "(bx.set_axis_labels(\"Type\", \"Number of Pets\")\n",
    "    .set_xticklabels([\"Dogs\", \"Cats\"])\n",
    "    .set_titles(\"{col_name} {col_var}\")\n",
    "    .despine(left=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','Type', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, the number of examples of dogs and cats is fairly proportional, as well as their relative distribution among target classes. \n",
    "Looking at the gain table, it is clear that dogs (1) tend to get adopted later relative to cats (2), which we can see by the growing relative gain. In fact, the number of dogs with no adoption after 100 days (`AdoptionSpeed = 4`) is 37% higher than dogs being adopted on the same day (`AdoptionSpeed = 0`). On the other hand, we observe the opposite phenomena on cats. They tend to be adopted at ealier stages, being the number of cats with no adoption after 100 days (`AdoptionSpeed = 4`) is 29% lower than cats being adopted on the same day (`AdoptionSpeed = 0`).\n",
    "Despite this small discrepancies, we expect the resulting models' performance to be comparable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "Since a reasonable amount of the profiles didn't make any reference to name (empty) a first approach would be to fill those empty values with a fixed value such as \"No Name\" or similar.\n",
    "Other approach would be to transform this feature into a binary one with a 0 value for profiles with no name and a 1 value for the opposite.\n",
    "Since it was later found that some of the named profiles were filled with \"No Name\" and derivatives of this name such as \"No Name Yet\", \"V6\", \"å°è±¹çº¹\" etc., which are not proper names, we made an attempt to classify those cases as \"No name\" as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A glimpse on the ignored names: ['No Name Yet', 'No Name', 'No Name', 'H3', 'Z3', 'C', 'No Name', 'No Name', 'BB', 'QQ', 'Y1', 'No Name', 'H1', 'No Name Yet', 'D9', 'Y4', 'No Name', 'Z4', 'No Name', 'Unnamed', 'BB', 'DD', 'M2', 'H6', 'D4', 'QQ', 'JJ', 'No Names', 'å°\\x8fè±¹çº¹', 'ä¼\\x98ç¾\\x8eå\\x8f¯ç¬\\x91', 'F1', 'æ©\\x98å\\xad\\x90', 'W7', '(No Name)', 'No Name Yet', 'No Name', '1F', 'Q1', '6', 'CJ', '3F', '[No Name]', 'BB', 'KD', 'No Name Yet', 'No Name Yet', 'DD', 'No Name', 'G1', 'è\\x8f\\x9cè\\x8f\\x9cã\\x80\\x82']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEMCAYAAAABLFv3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAeKUlEQVR4nO3df1AU9/3H8efpnWcUO8SUA2uN09hYZ7xWW86k5seRpomAwBjP2Cok1CbWhBqDtoEScaBkJCSGKElanDZxbMfEJjQxkDpwJlOL1h9NkI5GGjMmqdgKBo5CIqDgcdz3j4T7isaIrMeBvh7/HPthd+/9cXBf+9nP7Z7J7/f7ERERMWBYqAsQEZGhT2EiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYlhQw6StrY3ExESOHTvWq/3FF1/k3nvvDSzX19eTkpJCXFwcaWlptLe3A3DixAmWLFlCfHw8KSkpeDweAE6fPk1GRgbx8fHMnTuXjz76KJjdEBGRCwhamBw4cICFCxdSW1vbq/3DDz/k97//fa+2vLw8kpOTcbvd2O12iouLASgqKsLhcFBRUcH8+fPJz88HYNOmTVx11VVUVFSwcuVKHn300WB1Q0RE+sAcrB2XlJSQm5tLZmZmoO306dPk5OTw8MMPU1ZWBoDX66Wqqorf/va3ALhcLu655x4yMjKorKzkpZdeAiAxMZHHHnsMr9dLZWUl6enpAMyYMYPm5mbq6+v52te+dsG6uru7aW9vx2KxYDKZLnW3RUQuS36/H6/Xy+jRoxk27NxxSNDCpGcUcaann36aefPm8fWvfz3Q1tLSQlhYGGbzZ6VERETQ0NAAQGNjIxEREZ8VajYTFhZGc3Nzr/aebT7++OM+hUl7ezuHDx821DcRkSvV5MmTGTNmzDntAzYBv3v3bo4fP868efN6tfv9/nNGCOcbMfj9foYNG3bONj3tfWGxWC6ychER6XG+Y2jQRiZn27p1Kx988AFz5szh5MmTNDU1sXz5cp566ilaW1vx+XwMHz4cj8eDzWYDwGaz0dTURFRUFF1dXbS3txMeHk5kZCSNjY1ce+21ADQ1NQW2uZCeELLb7Vit1uB0VkTkMtPZ2UlNTc15T/YHbGRSUFBARUUFZWVlrF69GrvdTlFRERaLBYfDQXl5OQClpaU4nU4AYmJiKC0tBaC8vByHw4HFYiEmJiYw57Jv3z6sVmufLnGJiEhwDIr7THJzcykpKWH27Nns27eP5cuXA5Cens7+/ftJSEhg8+bN5OTkAHDvvfdy+vRpEhISyM/PZ82aNaEsX0Tkime60h5B3zNU02UuEZG+u9Cxc1CMTEREZGhTmIiIiGEKExERMUxhIiIihilMRC5D3V3eUJcgg1Aw/y4G7KZFERk4w8wWqtcsDnUZMshEZ74QtH1rZCIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETEs6GHS1tZGYmIix44dA+CVV14hMTGRpKQkHn30UU6fPg3AoUOHcLlcxMbGkp2dTVdXFwD19fWkpKQQFxdHWloa7e3tAJw4cYIlS5YQHx9PSkoKHo8n2F0REZHzCGqYHDhwgIULF1JbWwvAkSNH2LBhAy+//DJvvPEG3d3dbN68GYCMjAxycnLYtm0bfr+fkpISAPLy8khOTsbtdmO32ykuLgagqKgIh8NBRUUF8+fPJz8/P5hdERGRLxHUMCkpKSE3NxebzQbAiBEjyM3NJSwsDJPJxOTJk6mvr6euro6Ojg6mT58OgMvlwu124/V6qaqqIjY2tlc7QGVlJUlJSQAkJiayc+dOvF5977WISCgE9Tvgzx4tjB8/nvHjxwPQ3NzMSy+9REFBAY2NjURERATWi4iIoKGhgZaWFsLCwjCbzb3agV7bmM1mwsLCaG5uJjIysk+11dTUGO6fyGAVHR0d6hJkkKqurg7KfoMaJufT0NDA4sWLmTdvHjfeeCPV1dWYTKbA7/1+PyaTKfB6prOXz9xm2LC+D7TsdjtWq7V/HRARGaL6e6LR2dn5pSfhA/5pro8++ogFCxYwd+5cli5dCkBUVFSvCfSmpiZsNhtjx46ltbUVn88HgMfjCVwys9lsNDU1AdDV1UV7ezvh4eED3BsREYEBDpO2tjbuv/9+0tPTue+++wLt48ePx2q1BoZfZWVlOJ1OLBYLDoeD8vJyAEpLS3E6nQDExMRQWloKQHl5OQ6HA4vFMpDdERGRzw1omLz66qs0NTWxceNG5syZw5w5c3jmmWcAKCwspKCggLi4OE6ePElqaioAubm5lJSUMHv2bPbt28fy5csBSE9PZ//+/SQkJLB582ZycnIGsisiInIGk9/v94e6iIHUc91PcyZyuateszjUJcggE535Qr+3vdCxU3fAi4iIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYpjCREREDFOYiIiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYpjCREREDFOYiIiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcOCHiZtbW0kJiZy7NgxAPbs2UNSUhKzZs1i3bp1gfUOHTqEy+UiNjaW7Oxsurq6AKivryclJYW4uDjS0tJob28H4MSJEyxZsoT4+HhSUlLweDzB7oqIiJxHUMPkwIEDLFy4kNraWgA6OjpYuXIlxcXFlJeXU1NTw44dOwDIyMggJyeHbdu24ff7KSkpASAvL4/k5GTcbjd2u53i4mIAioqKcDgcVFRUMH/+fPLz84PZFRER+RJBDZOSkhJyc3Ox2WwAvPvuu0ycOJEJEyZgNptJSkrC7XZTV1dHR0cH06dPB8DlcuF2u/F6vVRVVREbG9urHaCyspKkpCQAEhMT2blzJ16vN5jdERGR8zAHc+dnjxYaGxuJiIgILNtsNhoaGs5pj4iIoKGhgZaWFsLCwjCbzb3az96X2WwmLCyM5uZmIiMj+1RbTU2Nob6JDGbR0dGhLkEGqerq6qDsN6hhcrbu7m5MJlNg2e/3YzKZztve83qms5fP3GbYsL4PtOx2O1ar9SJ7ICIytPX3RKOzs/NLT8IH9NNcUVFRvSbKPR4PNpvtnPampiZsNhtjx46ltbUVn8/Xa334bFTT1NQEQFdXF+3t7YSHhw9gb0REpMeAhsm0adM4cuQIR48exefzsXXrVpxOJ+PHj8dqtQaGX2VlZTidTiwWCw6Hg/LycgBKS0txOp0AxMTEUFpaCkB5eTkOhwOLxTKQ3RERkc8N6GUuq9XKE088wbJly+js7CQmJoa4uDgACgsLWbVqFW1tbUydOpXU1FQAcnNzycrKYv369YwbN461a9cCkJ6eTlZWFgkJCYwZM4bCwsKB7IqIiJzB5Pf7/aEuYiD1XPfTnIlc7qrXLA51CTLIRGe+0O9tL3Ts1B3wIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExLCQhElZWRkJCQkkJCTw5JNPAnDo0CFcLhexsbFkZ2fT1dUFQH19PSkpKcTFxZGWlkZ7ezsAJ06cYMmSJcTHx5OSkoLH4wlFV0REhBCEyalTp8jPz2fTpk2UlZWxb98+9uzZQ0ZGBjk5OWzbtg2/309JSQkAeXl5JCcn43a7sdvtFBcXA1BUVITD4aCiooL58+eTn58/0F0REZHPDXiY+Hw+uru7OXXqFF1dXXR1dWE2m+no6GD69OkAuFwu3G43Xq+XqqoqYmNje7UDVFZWkpSUBEBiYiI7d+7E6/UOdHdERAQwD/QbhoWFkZ6eTnx8PFdddRUzZszAYrEQERERWCciIoKGhgZaWloICwvDbDb3agdobGwMbGM2mwkLC6O5uZnIyMg+1VFTU3OJeyYyeERHR4e6BBmkqqurg7LfAQ+T999/n9dee42//e1vjBkzhkceeYTdu3djMpkC6/j9fkwmU+D1TGcvn7nNsGF9H2jZ7XasVmv/OiEiMkT190Sjs7PzS0/CB/wy165du5g5cybXXHMNI0aMwOVy8fbbb/eaQG9qasJmszF27FhaW1vx+XwAeDwebDYbADabjaamJgC6urpob28nPDx8oLsjIiL0MUx6Li2d6cMPP+zXG06ZMoU9e/Zw8uRJ/H4/27dv54YbbsBqtQaGX2VlZTidTiwWCw6Hg/LycgBKS0txOp0AxMTEUFpaCkB5eTkOhwOLxdKvmkRExJgvvcz1ySefAPCzn/2MTZs24ff7gc9GAg899FBgMvxi3HLLLbz33nu4XC4sFgvf/va3WbJkCXfeeSerVq2ira2NqVOnkpqaCkBubi5ZWVmsX7+ecePGsXbtWgDS09PJysoiISGBMWPGUFhYeNG1iIjIpWHy9yTEF7j//vvZvXv3Oe1ms5nY2FiefvrpoBYXDD3X/TRnIpe76jWLQ12CDDLRmS/0e9sLHTu/dGSyYcMGAB599FEKCgr6XYSIiFze+vRproKCAurq6vj00085cyAzderUoBUmIiJDR5/C5Nlnn2XDhg1cc801gTaTycRf//rXoBUmIiJDR5/CpLS0lDfffLPPNwSKiMiVpU8fDR43bpyCREREzqtPI5OZM2eyZs0afvjDHzJy5MhAu+ZMREQE+hgmW7ZsAeh1X4nmTEREpEefwmT79u3BrkNERIawPoXJxo0bv7D9pz/96SUtRkREhqY+hcnhw4cDP58+fZqqqipmzpwZtKJERGRo6fNNi2dqaGggOzs7KAWJiMjQ069H0EdGRlJXV3epaxERkSHqoudM/H4/NTU1ve6GFxGRK9tFz5nAZzcxZmZmBqUgEREZei5qzqSuro6uri4mTpwY1KJERGRo6VOYHD16lJ///Oc0NjbS3d3N1Vdfze9+9zsmTZoU7PpERGQI6NME/GOPPcbixYupqqqiurqatLQ08vLygl2biIgMEX0Kk//973/MnTs3sDxv3jxaWlqCVpSIiAwtfQoTn88X+D54gObm5qAVJCIiQ0+f5kzuuecefvzjHxMfH4/JZKK8vJyf/OQnwa5NRESGiD6NTGJiYgDwer189NFHNDQ0cOeddwa1MBERGTr6NDLJysoiJSWF1NRUOjs7+dOf/sTKlSt5/vnng12fiIgMAX0ambS0tJCamgqA1Wpl0aJFeDyefr/p9u3bcblcxMfHs3r1agD27NlDUlISs2bNYt26dYF1Dx06hMvlIjY2luzsbLq6ugCor68nJSWFuLg40tLSaG9v73c9IiJiTJ8n4BsaGgLLTU1N+P3+fr3hf//7X3JzcykuLuaNN97gvffeY8eOHaxcuZLi4mLKy8upqalhx44dAGRkZJCTk8O2bdvw+/2UlJQAkJeXR3JyMm63G7vdTnFxcb/qERER4/oUJosWLeKuu+4iMzOTX/3qV8ydO5fFixf36w3feustZs+eTVRUFBaLhXXr1nHVVVcxceJEJkyYgNlsJikpCbfbTV1dHR0dHUyfPh0Al8uF2+3G6/VSVVVFbGxsr3YREQmNPs2Z3H333djtdv7xj38wfPhw7r//fiZPntyvNzx69CgWi4UHH3yQ48ePc9ttt3H99dcTERERWMdms9HQ0EBjY2Ov9oiICBoaGmhpaSEsLAyz2dyr/WLU1NT0q36RoSA6OjrUJcggVV1dHZT99ilMAKZMmcKUKVMMv6HP52Pfvn1s2rSJUaNGkZaWxsiRIzGZTIF1/H4/JpOJ7u7uL2zveT3T2csXYrfbsVqtxjojIjLE9PdEo7Oz80tPwvscJpfKV7/6VWbOnMnYsWMBuOOOO3C73QwfPjywjsfjwWazERUV1Wuiv6mpCZvNxtixY2ltbcXn8zF8+PDA+iIiEhr9+nIsI37wgx+wa9cuTpw4gc/n4+9//ztxcXEcOXKEo0eP4vP52Lp1K06nk/Hjx2O1WgPDsrKyMpxOJxaLBYfDQXl5OQClpaU4nc6B7oqIiHxuwEcm06ZNY/HixSQnJ+P1ern55ptZuHAh1113HcuWLaOzs5OYmBji4uIAKCwsZNWqVbS1tTF16tTAR5Rzc3PJyspi/fr1jBs3jrVr1w50V0RE5HMmf38/4ztE9Vz305yJXO6q1/TvE5dy+YrOfKHf217o2Dngl7lEROTyozARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMSykYfLkk0+SlZUFwKFDh3C5XMTGxpKdnU1XVxcA9fX1pKSkEBcXR1paGu3t7QCcOHGCJUuWEB8fT0pKCh6PJ2T9EBG50oUsTPbu3cvrr78eWM7IyCAnJ4dt27bh9/spKSkBIC8vj+TkZNxuN3a7neLiYgCKiopwOBxUVFQwf/588vPzQ9IPEREJUZh88sknrFu3jgcffBCAuro6Ojo6mD59OgAulwu3243X66WqqorY2Nhe7QCVlZUkJSUBkJiYyM6dO/F6vSHojYiImEPxpjk5OaxYsYLjx48D0NjYSEREROD3ERERNDQ00NLSQlhYGGazuVf72duYzWbCwsJobm4mMjKyTzXU1NRcyi6JDCrR0dGhLkEGqerq6qDsd8DD5M9//jPjxo1j5syZbNmyBYDu7m5MJlNgHb/fj8lkCrye6ezlM7cZNqzvAy273Y7Vau1HD0REhq7+nmh0dnZ+6Un4gIdJeXk5Ho+HOXPm8Omnn3Ly5ElMJlOvCfSmpiZsNhtjx46ltbUVn8/H8OHD8Xg82Gw2AGw2G01NTURFRdHV1UV7ezvh4eED3R0RESEEcyYbN25k69atlJWV8fDDD3P77bdTUFCA1WoNDL/KyspwOp1YLBYcDgfl5eUAlJaW4nQ6AYiJiaG0tBT4LKAcDgcWi2WguyMiIgyi+0wKCwspKCggLi6OkydPkpqaCkBubi4lJSXMnj2bffv2sXz5cgDS09PZv38/CQkJbN68mZycnFCWLyJyRTP5/X5/qIsYSD3X/TRnIpe76jWLQ12CDDLRmS/0e9sLHTsHzchERESGLoWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEKExERMUxhIiIihilMRETEMIWJiIgYpjARERHDFCYiImKYwkRERAxTmIiIiGEhCZPf/OY3JCQkkJCQwJo1awDYs2cPSUlJzJo1i3Xr1gXWPXToEC6Xi9jYWLKzs+nq6gKgvr6elJQU4uLiSEtLo729PRRdERERQhAme/bsYdeuXbz++uuUlpbyr3/9i61bt7Jy5UqKi4spLy+npqaGHTt2AJCRkUFOTg7btm3D7/dTUlICQF5eHsnJybjdbux2O8XFxQPdFRER+dyAh0lERARZWVmMGDECi8XCpEmTqK2tZeLEiUyYMAGz2UxSUhJut5u6ujo6OjqYPn06AC6XC7fbjdfrpaqqitjY2F7tIiISGuaBfsPrr78+8HNtbS0VFRXcc889REREBNptNhsNDQ00Njb2ao+IiKChoYGWlhbCwsIwm8292i9GTU2NwZ6IDF7R0dGhLkEGqerq6qDsd8DDpMcHH3zAAw88QGZmJsOHD6e2tjbwO7/fj8lkoru7G5PJdE57z+uZzl6+ELvdjtVqNdQHEZGhpr8nGp2dnV96Eh6SCfjq6moWLVrEL3/5S+bOnUtUVBQejyfwe4/Hg81mO6e9qakJm83G2LFjaW1txefz9VpfRERCY8DD5Pjx4yxdupTCwkISEhIAmDZtGkeOHOHo0aP4fD62bt2K0+lk/PjxWK3WwLCsrKwMp9OJxWLB4XBQXl4OQGlpKU6nc6C7IiIinxvwy1wbNmygs7OTJ554ItC2YMECnnjiCZYtW0ZnZycxMTHExcUBUFhYyKpVq2hra2Pq1KmkpqYCkJubS1ZWFuvXr2fcuHGsXbt2oLsiIiKfM/n9fn+oixhIPdf9NGcil7vqNYtDXYIMMtGZL/R72wsdO3UHfD+d9vpCXYIMQvq7kCtVyD7NNdSNsAwnOfOlUJchg8zmNSmhLkEkJDQyERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChMRETFMYSIiIoYpTERExDCFiYiIGKYwERERwxQmIiJimMJEREQMU5iIiIhhQzpM/vKXvzB79mxmzZrFSy+9FOpyRESuWOZQF9BfDQ0NrFu3ji1btjBixAgWLFjAjTfeyDe/+c1QlyYicsUZsmGyZ88evv/97xMeHg5AbGwsbrebhx566Eu38/v9AJw+fdpwDV8ZZTG8D7m8dHZ2hrqE/zdyTKgrkEHGyN9nzzGz5xh6tiEbJo2NjURERASWbTYb77777gW383q9ABw+fNhwDT9LmmR4H3J5qampCXUJ/+/me0JdgQwyl+Lv0+v1MnLkyHPah2yYdHd3YzKZAst+v7/X8vmMHj2ayZMnY7FY+rS+iIh8doz1er2MHj36C38/ZMMkKiqKffv2BZY9Hg82m+2C2w0bNowxYzT8FxG5WF80IukxZD/NddNNN7F3716am5s5deoUb775Jk6nM9RliYhckYbsyCQyMpIVK1aQmpqK1+vl7rvv5jvf+U6oyxIRuSKZ/OebmhcREemjIXuZS0REBg+FiYiIGKYwERERwxQmIiJimMJEDNHDNmUwa2trIzExkWPHjoW6lMuewkT6redhm5s3b6a0tJRXXnmFDz/8MNRliQBw4MABFi5cSG1tbahLuSIoTKTfznzY5qhRowIP2xQZDEpKSsjNze3TkzHEuCF706KEXn8ftikyEPLz80NdwhVFIxPpt/4+bFNELj8KE+m3qKgoPB5PYLmvD9sUkcuPwkT6TQ/bFJEemjORftPDNkWkhx70KCIihukyl4iIGKYwERERwxQmIiJimMJEREQMU5iIiIhhChORi/D222+TmJh4SfZ1++23k5GR0avt4MGD3H777Zdk/yIDSWEiEkJut5uysrJQlyFimG5aFLlIJ0+eZMWKFfz73/+ms7OT1atXc8011/DYY4/R3t6Ox+NhypQpFBUVYbVaefbZZ3nrrbewWCxcffXVFBQUBB47s2LFClavXs33vvc9JkyYcM77/PrXv+bo0aN88sknjB49msLCQq677jruvfdepk6dyv79+2lubuZHP/oRTU1NvPPOO5w6dYqioiK+9a1v0draSn5+PocPH8br9TJz5kwyMzMxm/VfXy4tjUxELtLHH3/MokWLKCsrY8GCBTz33HOUlJRw1113UVJSwptvvsmxY8eorKzk+PHj/PGPf+S1115jy5Yt3Hzzzb2erDxjxgySk5N55JFH6Orq6vU+O3fu5Ctf+QqvvPIK27Ztw2639/oCsrq6Ol5++WWeeuopnnrqKW644Qa2bNnCrbfeyosvvgjA448/ztSpU9myZQulpaW0tLSwcePGgfmHkiuKTk9ELtKECROYNm0aAFOmTOG1114jIyOD3bt38/zzz1NbW0tjYyMnT54kMjKSKVOmMHfuXJxOJ06nk5kzZ/ba37Jly9i7dy/PPfccd9xxR6A9Li6OCRMmsGnTJo4ePco777zDd7/73cDv77zzzkA9ALfeeisA1157Le+88w4AlZWVHDx4kFdffRWAjo6OIP2ryJVOYSJykSwWS+Bnk8mE3+/nF7/4BT6fj/j4eG677TaOHz+O3+9n2LBhvPjiixw8eJC9e/fy+OOPc+utt5KZmRnYh9ls5umnn8blchEeHh5o37x5MyUlJaSkpJCUlER4eHivr58dMWLEeevq0d3dzTPPPMOkSZMAOHHihL4mQIJCl7lELoFdu3axdOlSZs+eDXz2lbE+n4/333+fxMREJk2axAMPPMCiRYs4ePDgOdtPmDCB7Oxs1q5d22ufc+fOZf78+XzjG99g+/bt+Hy+i6rrlltu4Q9/+AN+v5/Tp0+TlpYWuAQmcilpZCJyCaxYsYKlS5cyatQowsLCmDFjBv/5z3+YP38+8fHxzJs3j1GjRjFy5EhWrVr1hfu466672LVrF//85z8BuO+++8jJyQlcopo+fTqHDx++qLqys7PJz88nKSkJr9fLTTfdxOLFi411VuQL6KnBIiJimC5ziYiIYQoTERExTGEiIiKGKUxERMQwhYmIiBimMBEREcMUJiIiYpjCREREDPs/ymItpAziVI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create new feature - hasNames\n",
    "l = []\n",
    "ignore = []\n",
    "\n",
    "for i in df[\"Name\"]:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        l.append(0)\n",
    "    else:\n",
    "        if len(i)<3: #Consider that a 2 letter name is not a proper name.\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif re.search(\"[a-zA-Z]\", i) == None: #If name doesn't have letters, it's not a proper name.\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif re.search(\"unnamed|no name\",i, re.IGNORECASE) != None: \n",
    "            #If name string includes \"unnamed\" or \"no name\", it's not a proper name\n",
    "            l.append(0)\n",
    "            ignore.append(i)\n",
    "        elif len(i.split())>0:\n",
    "            l.append(1)\n",
    "\n",
    "print(\"A glimpse on the ignored names:\",ignore[:50])\n",
    "df_processed1 = df.copy()\n",
    "df_processed1.drop(\"Name\", axis=1, inplace = True)\n",
    "df_processed1.insert(1,\"hasName\",l) ##INSERT IN DATAFRAME\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.countplot(x=\"hasName\", data=df_processed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','hasName', df_processed1, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, the relative distribution of the \"noName\" feature values among `AdoptionSpeed` classes is very similar. This probabably means that the pet's name is not a very important factor in the adopter's decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "When looking at `Age` distribution, we can see that there are peaks every 12 months. Young pets (less than 1 year old) are the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFACAYAAAAF72WkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfXQU9aH/8U+SXSI0eHnaJRyMXJ8wLSicGrUoJMVKEkgCEh94iGClGECLSCsaIJLKVQEvF6wVUHrUtojaiJAAN0ZRCgIBBY5KlVQRBJHwCxsByXN2N9/fH5S9JCRAsiG7jO/XOR7c2dnxM+t+Z+bDzM6GGGOMAAAAAACWEhroAAAAAACAlkfZAwAAAAALouwBAAAAgAVR9gAAAADAgih7AAAAAGBBlD0AAAAAsKDzKntlZWVKTk7Wd999J0kqKChQSkqK4uPjtXDhQt98hYWFSk1NVUJCgmbOnCmPxyNJKioqUlpamhITEzVp0iSVl5dLkk6cOKH09HQNHjxYaWlpcrlcLb1+AAAAAPCjFHKu39n77LPPlJmZqW+++Ub5+fnq0qWLEhMTtWzZMnXr1k0TJkzQ2LFjFRcXp+TkZD311FPq27evZsyYod69e2v06NGaMGGChg4dqqSkJC1atEgVFRWaNm2aZs+ercjISKWnpysnJ0cbNmzQc88916QVOHasXLW1wftTgZ07R+j778sCHaNR5PMP+fwT7Pmk4M9IPv+Qzz/Bnk8K/ozk8w/5/BPs+aTgzxjofKGhIerY8SeNPm871wKys7OVlZWlxx57TJK0a9cu9ejRQ1FRUZKklJQU5efn6+qrr1ZVVZX69u0rSUpNTdXzzz+vu+++W9u3b9eiRYt80++9915NmzZNGzZs0PLlyyVJycnJmj17ttxut+x2+3mvYG2tCeqyJ4l8fiKff8jnv2DPSD7/kM8/wZ5PCv6M5PMP+fwT7Pmk4M8YzPnOWfaefvrpOo+PHDkih8Phe+x0OlVcXHzGdIfDoeLiYh07dkwRERGy2Wx1ptdfls1mU0REhI4ePaquXbv6v2YAAAAA8CN2zrJXX21trUJCQnyPjTEKCQlpdPqpP09X//HprwkNbdo9Yzp3jmjS/IHgcLQPdISzIp9/yOefYM8nBX9G8vmHfP4J9nxS8Gckn3/I559gzycFf8ZgztfkshcZGVnnRioul0tOp/OM6SUlJXI6nerUqZNKS0vl9XoVFhbmm186eVawpKREkZGR8ng8Ki8vV4cOHZqU5/vvy4L61KnD0V4uV2mgYzSKfP4hn3+CPZ8U/BnJ5x/y+SfY80nBn5F8/iGff4I9nxT8GQOdLzQ05Kwnv5r80wt9+vTRN998owMHDsjr9Wrt2rWKjY1V9+7dFR4erp07d0qScnNzFRsbK7vdrpiYGOXl5UmScnJyFBsbK0mKi4tTTk6OJCkvL08xMTFN+r4eAAAAAKBhTT6zFx4errlz52ry5Mmqrq5WXFycEhMTJUnz589XZmamysrK1KtXL40dO1aSlJWVpYyMDC1ZskTdunXTggULJElTpkxRRkaGkpKS1L59e82fP78FVw0AAAAAfrzOu+ytX7/e9+/9+vXT6tWrz5gnOjpaK1asOGN69+7dtWzZsjOmd+jQQS+++OL5RgAAAAAAnKcmX8YJAAAAAAh+lD0AAAAAsCDKHgAAAABYEGUPAAAAACyoyXfjDDaVNV55vLV+LSPcbpON2gsAAADAQi76svfZ1yWqqHL7tYwbf9pVtvCL/q0AAAAAAB/OZwEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAW5FfZy83NVVJSkpKSkjRv3jxJUmFhoVJTU5WQkKCZM2fK4/FIkoqKipSWlqbExERNmjRJ5eXlkqQTJ04oPT1dgwcPVlpamlwul5+rBAAAAABodtmrrKzU008/rWXLlik3N1c7duxQQUGBpk2bplmzZundd9+VMUbZ2dmSpCeffFKjR49Wfn6+evfurcWLF0uSnnvuOcXExOidd97R3Xffraeffrpl1gwAAAAAfsSaXfa8Xq9qa2tVWVkpj8cjj8cjm82mqqoq9e3bV5KUmpqq/Px8ud1ubd++XQkJCXWmS9KGDRuUkpIiSUpOTtaHH34ot9vt73oBAAAAwI+arbkvjIiI0JQpUzR48GC1bdtWN954o+x2uxwOh28eh8Oh4uJiHTt2TBEREbLZbHWmS9KRI0d8r7HZbIqIiNDRo0fVtWtXf9YLAAAAAH7Uml32/vWvf+ntt9/WP/7xD7Vv316PPvqotmzZopCQEN88xhiFhIT4/jxd/cenvyY09PxPOEb8JFxhtrDmrcS/tWsXLkendn4t42wcjvYXbNktgXz+IZ9/gj2fFPwZyecf8vkn2PNJwZ+RfP4hn3+CPZ8U/BmDOV+zy97mzZvVr18/de7cWdLJSzNffvnlOjdYKSkpkdPpVKdOnVRaWiqv16uwsDC5XC45nU5JktPpVElJiSIjI+XxeFReXq4OHTqcd46y8mpVVPl32WdFRbVcXq9fy2iMw9FeLlfpBVl2SyCff8jnn2DPJwV/RvL5h3z+CfZ8UvBnJJ9/yOefYM8nBX/GQOcLDQ1R584RjT/f3AVHR0eroKBAFRUVMsZo/fr1uummmxQeHq6dO3dKOnm3ztjYWNntdsXExCgvL0+SlJOTo9jYWElSXFyccnJyJEl5eXmKiYmR3W5vbiwAAAAAgPw4s9e/f3/t3r1bqampstvtuu6665Senq5BgwYpMzNTZWVl6tWrl8aOHStJysrKUkZGhpYsWaJu3bppwYIFkqQpU6YoIyNDSUlJat++vebPn98yawYAAAAAP2LNLnuSlJ6ervT09DrToqOjtWLFijPm7d69u5YtW3bG9A4dOujFF1/0JwYAAAAAoB6/flQdAAAAABCcKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALIiyBwAAAAAWRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFiQX2Vv/fr1Sk1N1eDBg/XUU09JkgoKCpSSkqL4+HgtXLjQN29hYaFSU1OVkJCgmTNnyuPxSJKKioqUlpamxMRETZo0SeXl5f5EAgAAAADIj7J38OBBZWVlafHixVq9erV2796tjRs3asaMGVq8eLHy8vL0+eefa+PGjZKkadOmadasWXr33XdljFF2drYk6cknn9To0aOVn5+v3r17a/HixS2zZgAAAADwI9bssrdu3ToNGTJEkZGRstvtWrhwodq2basePXooKipKNptNKSkpys/P16FDh1RVVaW+fftKklJTU5Wfny+3263t27crISGhznQAAAAAgH9szX3hgQMHZLfbNXHiRB0+fFi//OUvdc0118jhcPjmcTqdKi4u1pEjR+pMdzgcKi4u1rFjxxQRESGbzVZnOgAAAADAP80ue16vVzt27NCyZcvUrl07TZo0SZdccolCQkJ88xhjFBISotra2gann/rzdPUfn0vET8IVZgtr7mpIktq1C5ejUzu/lnE2Dkf7C7bslkA+/5DPP8GeTwr+jOTzD/n8E+z5pODPSD7/kM8/wZ5PCv6MwZyv2WWvS5cu6tevnzp16iRJuv3225Wfn6+wsP8rXi6XS06nU5GRkXK5XL7pJSUlcjqd6tSpk0pLS+X1ehUWFuabvynKyqtVUeVu7mpIkioqquXyev1aRmMcjvZyuUovyLJbAvn8Qz7/BHs+Kfgzks8/5PNPsOeTgj8j+fxDPv8Eez4p+DMGOl9oaIg6d45o/PnmLnjgwIHavHmzTpw4Ia/Xq02bNikxMVHffPONDhw4IK/Xq7Vr1yo2Nlbdu3dXeHi4du7cKUnKzc1VbGys7Ha7YmJilJeXJ0nKyclRbGxscyMBAAAAAP6t2Wf2+vTpo/Hjx2v06NFyu9269dZbNWrUKF155ZWaPHmyqqurFRcXp8TEREnS/PnzlZmZqbKyMvXq1Utjx46VJGVlZSkjI0NLlixRt27dtGDBgpZZMwAAAAD4EWt22ZOku+66S3fddVedaf369dPq1avPmDc6OlorVqw4Y3r37t21bNkyf2IAAAAAAOrx60fVAQAAAADBibIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIL8Lnvz5s1TRkaGJKmwsFCpqalKSEjQzJkz5fF4JElFRUVKS0tTYmKiJk2apPLycknSiRMnlJ6ersGDBystLU0ul8vfOAAAAAAA+Vn2tm7dqlWrVvkeT5s2TbNmzdK7774rY4yys7MlSU8++aRGjx6t/Px89e7dW4sXL5YkPffcc4qJidE777yju+++W08//bQ/cQAAAAAA/9bssnf8+HEtXLhQEydOlCQdOnRIVVVV6tu3ryQpNTVV+fn5crvd2r59uxISEupMl6QNGzYoJSVFkpScnKwPP/xQbrfbrxUCAAAAAPhR9mbNmqWpU6fq0ksvlSQdOXJEDofD97zD4VBxcbGOHTumiIgI2Wy2OtPrv8ZmsykiIkJHjx5t9soAAAAAAE6yNedFb731lrp166Z+/fpp5cqVkqTa2lqFhIT45jHGKCQkxPfn6eo/Pv01oaFN658RPwlXmC2siWtQV7t24XJ0aufXMs7G4Wh/wZbdEsjnH/L5J9jzScGfkXz+IZ9/gj2fFPwZyecf8vkn2PNJwZ8xmPM1q+zl5eXJ5XJp2LBh+uGHH1RRUaGQkJA6N1gpKSmR0+lUp06dVFpaKq/Xq7CwMLlcLjmdTkmS0+lUSUmJIiMj5fF4VF5erg4dOjQpS1l5tSqq/Lv0s6KiWi6v169lNMbhaC+Xq/SCLLslkM8/5PNPsOeTgj8j+fxDPv8Eez4p+DOSzz/k80+w55OCP2Og84WGhqhz54jGn2/OQl999VWtXbtWubm5evjhh3Xbbbdpzpw5Cg8P186dOyVJubm5io2Nld1uV0xMjPLy8iRJOTk5io2NlSTFxcUpJydH0skCGRMTI7vd3pxIAAAAAIDTtOjv7M2fP19z5sxRYmKiKioqNHbsWElSVlaWsrOzNWTIEO3YsUOPPPKIJGnKlCn69NNPlZSUpNdff12zZs1qyTgAAAAA8KPVrMs4T5eamqrU1FRJUnR0tFasWHHGPN27d9eyZcvOmN6hQwe9+OKL/kYAAAAAANTTomf2AAAAAADBgbIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIL8KnsvvPCCkpKSlJSUpGeffVaSVFBQoJSUFMXHx2vhwoW+eQsLC5WamqqEhATNnDlTHo9HklRUVKS0tDQlJiZq0qRJKi8v9ycSAAAAAEB+lL2CggJt3rxZq1atUk5Ojr744gutXbtWM2bM0OLFi5WXl6fPP/9cGzdulCRNmzZNs2bN0rvvvitjjLKzsyVJTz75pEaPHq38/Hz17t1bixcvbpk1AwAAAIAfsWaXPYfDoYyMDLVp00Z2u11XXXWV9u/frx49eigqKko2m00pKSnKz8/XoUOHVFVVpb59+0qSUlNTlZ+fL7fbre3btyshIaHOdAAAAACAf5pd9q655hpfedu/f7/eeecdhYSEyOFw+OZxOp0qLi7WkSNH6kx3OBwqLi7WsWPHFBERIZvNVmc6AAAAAMA/Nn8XsGfPHk2YMEGPPfaYwsLCtH//ft9zxhiFhISotrZWISEhZ0w/9efp6j8+l4ifhCvMFubXOrRrFy5Hp3Z+LeNsHI72F2zZLYF8/iGff4I9nxT8GcnnH/L5J9jzScGfkXz+IZ9/gj2fFPwZgzmfX2Vv586devjhhzVjxgwlJSXp448/lsvl8j3vcrnkdDoVGRlZZ3pJSYmcTqc6deqk0tJSeb1ehYWF+eZvirLyalVUuf1ZDVVUVMvl9fq1jMY4HO3lcpVekGW3BPL5h3z+CfZ8UvBnJJ9/yOefYM8nBX9G8vmHfP4J9nxS8GcMdL7Q0BB17hzR+PPNXfDhw4f10EMPaf78+UpKSpIk9enTR998840OHDggr9ertWvXKjY2Vt27d1d4eLh27twpScrNzVVsbKzsdrtiYmKUl5cnScrJyVFsbGxzIwEAAAAA/q3ZZ/ZefvllVVdXa+7cub5pI0eO1Ny5czV58mRVV1crLi5OiYmJkqT58+crMzNTZWVl6tWrl8aOHStJysrKUkZGhpYsWaJu3bppwYIFfq4SAAAAAKDZZS8zM1OZmZkNPrd69eozpkVHR2vFihVnTO/evbuWLVvW3BgAAAAAgAb49aPqAAAAAIDgRNkDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUPQAAAACwIMoeAAAAAFgQZQ8AAAAALKjZP6puJSGhISqv9rTIssLtNtmo0AAAAAACjLInqdrt1WdfuVpkWTf+tKts4bytAAAAAAKLc1AAAAAAYEGUPQAAAACwIMoeAAAAAFgQXy5rYfVv9mKOVqiiGTd/4UYvAAAAAPxB2Wth9W/20j7iEpWWVTV5OdzoBQAAAIA/OHcEAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgW6AD4MLy1ErVbk+jz5ujFaqobvz5U8LtNtn4qwEAAADgokHZs7hqt0fbC4sbfb59xCUqLas653Ju/GlX2cL5uAAAAAAXC87VAAAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4AAAAAWBBlDwAAAAAsiHvpo1Wd63f/6mvsdwD53T8AAADg7Ch7aFXn+t2/+hr7HUB+9w8AAAA4O86NAAAAAIAFcWokSIWEhqi8gcsXm6rWtEAYAAAAABcdyl6QqnZ79dlXLr+X06enowXSAAAAALjYUPbwo9fUm8ac7vQbyATbTWM8tdKRRm5w0xTBtl4AAAA4P5Q9/Og19aYxpzv9BjLBdtOYardH/9r3fYM3uGmKYFsvAAAAnJ+g+Pv6NWvWaMiQIYqPj9fy5csDHQcAAAAALnoB/+v64uJiLVy4UCtXrlSbNm00cuRI3Xzzzbr66qsDHQ2n4YYx8FdDl8s29juK59JSl5aezyW855ORS10BAEAwCnjZKygo0C9+8Qt16NBBkpSQkKD8/Hz99re/DXAynI4bxsBfDV0u29jvKJ5LS11aej6X8J5PRi51BQAAwSjgRydHjhyRw/F/BcDpdGrXrl3n/fq2LXCAZQsLVbtL7H4vp6FltQ23yetp+rJbKtO5lnO++VorT32N5bPZw1TtqfU7jySFhjZ/3U7P11KZ2tjCFNYCZ4lsYaHN/vzVX05oaEiL5Kn/PvszPi5UpvrOJ2NL5fHWSjUeb5NeU3K88ozPXUt9hlpKS7w3Le3Ue93Q+9cUrfFeB+P7d7pgzycFf0by+Yd8/gn2fFLwZwxkvnP9t0OMMQG9sG7JkiWqrq7WI488IknKzs7W559/rtmzZwcyFgAAAABc1AL+d7+RkZFyuf7v8kCXyyWn0xnARAAAAABw8Qt42bvlllu0detWHT16VJWVlXrvvfcUGxsb6FgAAAAAcFEL+Hf2unbtqqlTp2rs2LFyu9266667dP311wc6FgAAAABc1AL+nT0AAAAAQMsL+GWcAAAAAICWR9kDAAAAAAui7AEAAACABVH2AAAAAMCCKHsAAAAAYEGUvRZWVlam5ORkfffdd5Kkv//970pOTlZKSoqmT5+umpqagGV74YUXlJSUpKSkJD377LN1nnvttdc0ZsyYACU76Y9//KOGDBmipKQkvfrqq5KkTz75RPfcc4+SkpL0u9/9LqDv3ynz5s1TRkaGJOmLL77QnXfeqaFDh2rChAk6ceJEwHKtX79eqampGjx4sJ566ilJUkFBgVJSUhQfH6+FCxcGLJskvfXWWxo2bJjvnxtuuEGzZ88OqjGSm5vrGyPz5s2r89yGDRt02223BSjZSUuXLlVCQoJSUlK0ZMkSSdK+ffs0ZswYDR06VL/5zW/0ww8/tHqu+tu9xj53gRov57tdLiwsVGpqqhISEjRz5kx5PJ6A5Hv99deVlJSkIUOGaN68eTp10+z3339fw4YN09ChQ/Xggw+22v/r+vlOaWy/sXv3bvXu3btVsp1SP+P06dMVHx/v296sW7dOUuD2KfXzNZYjWMbI5s2bNXToUCUnJ+uxxx7z5SsqKlJaWpoSExM1adIklZeXByTfypUrNWTIEKWkpOipp57yjdWdO3fqrrvu0rBhw3Tffffp0KFDFzxbQ8dW59r3tvb+pLHjP7fbrfvuu08fffSRb1og9ikN5WtsOx2IMdKU4+dAjZGzMmgxn376qUlOTja9evUyBw8eNPv27TODBg0ypaWlpra21jz22GPm1VdfDUi2LVu2mBEjRpjq6mpTU1Njxo4da9577z1jjDF79uwxAwYMMPfee29AshljzEcffWRGjhxp3G63qaysNAMHDjSFhYXm1ltvNYWFhcYYY6ZOnWqWL18esIzGGFNQUGBuvvlm8/jjjxtjjBk1apTZsGGDMcaYOXPmmAULFgQk17fffmv69+9vDh8+bGpqany54uLizLfffmvcbrcZN26cL2ugffXVV2bQoEHms88+C5oxUlFRYW688Ubz/fffG7fbbe666y6zZcsWY4wxLpfLJCYmmoEDBwYkmzEnx3BycrIpLS01Ho/HTJgwweTn55v4+HizceNGY4wx//3f/22effbZVs1Vf7tXWVnZ6OcuEOOlKdvlpKQk88knnxhjjJk+fXqrbG/q5/v222/NoEGDTHl5ufF4PGbEiBFm06ZNprS01Nx6663m//2//2eMMea5554z//Vf/9Xq+U5pbL9RUVFhRo4caXr27HnBs50tY3JysikuLq4z36n3sLX3KfXznS1HMIwRY4yJjY01X3/9tTHGmMmTJ5vs7GxjjDHp6elm7dq1xhhjXnjhhVbZ3tTPt3fvXjNgwADf/9+srCzzyiuvGGOM79jBGGPeeustM3HixAuaraFjqzVr1px139va+5PGjv/27t1rRowYYa677jqzbds2Y4wxtbW1rb5PaSjfSy+91Oh2urXHSFOPnwMxRs6FM3stKDs7W1lZWXI6nZKkNm3aKCsrSxEREQoJCVHPnj1VVFQUkGwOh0MZGRlq06aN7Ha7rrrqKhUVFammpkazZs3Sww8/HJBcp9x0003629/+JpvNpu+//15er1eFhYXq27evoqOjJUmZmZkaNGhQwDIeP35cCxcu1MSJE33TamtrfX9rU1lZqUsuuSQg2datW6chQ4YoMjJSdrtdCxcuVNu2bdWjRw9FRUXJZrMpJSVF+fn5AclX3x/+8AdNnTpVnTt3Dpox4vV6VVtbq8rKSnk8Hnk8HoWHh0s6+dn77W9/G5Bcp+zevVv9+/dXRESEwsLCNGDAAK1atUrt2rVTbGysJGnixIlKS0tr1Vz1t3u7du1q9HMXiPFyvtvlQ4cOqaqqSn379pUkpaamtsp4qZ8vKqGZZ3YAABBdSURBVCpK//u//6t27drpxIkTKisr06WXXiq3262srCx17dpVknTttdfq8OHDrZ5P0ln3G3PnztV99913wXOdrn7GyspKFRUVacaMGUpJSdHzzz+v2tpabdmyJSD7lPr5zpYjGMaIdHJ7WFZWJq/Xq+rqaoWHh8vtdmv79u1KSEiQFLgx8uWXX6pv376+xwMHDtT777+vmpoaTZkyxfe+tsYYaejYav/+/Wfd97b2/qSx478VK1Zo/Pjx6tOnj2/eL774otX3KQ3lq6mpafTYoLXHSFOOnwM1Rs7FFugAVvL000/Xedy9e3d1795dknT06FEtX75cc+bMCUQ0XXPNNb5/379/v9555x298cYb+p//+R/deeeduuyyywKS63R2u13PP/+8XnnlFSUmJsrlcqldu3aaOnWq9u3bp5///Oe+yycDYdasWZo6dWqdnUdGRobGjRunZ555Rm3btlV2dnZAsh04cEB2u10TJ07U4cOH9ctf/lLXXHONHA6Hbx6n06ni4uKA5DtdQUGBqqqqNHjwYEkKmjESERGhKVOmaPDgwWrbtq1uvPFG/fznP9ff/vY3/exnP6uzQwyEXr166ZlnntGECRPUtm1brV+/Xps3b1ZsbKxmzJihwsJCXXnllXriiSdaNVf97d6RI0ca/dwFYryc73a5fm6Hw9Eq46V+PunktjA7O1vz5s3T9ddfr+joaLVp08ZXCKqqqrR06dJWufS+oXyN7Tc++OADVVVVKTEx8YLnOl39jCUlJfrFL36hrKwstW/fXhMmTNCKFSt0/PjxgOxT6uc7cOBAozmCYYxIJ/9CbsyYMYqIiNBll12mxMREHTt2TBEREbLZTh46BmqMREdHa+7cuTp8+LCcTqfy8/NVUlKiNm3aaNiwYZJOFoIXXnhBt99++wXN1tCx1b333tvoNjAQ+5PGjv/+8z//U5L017/+1ff8t99+qy5durTqPuVc+eofG7T2GGnK8XOgxsi5cGavFRQXF+u+++7TnXfeqZtvvjmgWfbs2aNx48bpscce06FDh3T48GHdeeedAc10uocfflhbt27V4cOHVVNTo82bN+t3v/udVq5cqcrKSi1dujQgud566y1169ZN/fr1802rqqrSzJkz9Ze//EWbN2/W6NGj9fjjjwckn9fr1datW/XMM8/o73//u3bt2qWDBw8qJCTEN48xps7jQHnzzTd1//3315kWDGPkX//6l95++2394x//0KZNmxQaGqrFixfrvffe04MPPhiQTKfr16+fUlNTNWbMGI0fP1433HCDJOnjjz/WqFGjtGrVKkVFRWnu3LkBzVlbW9vg5y6Yxot05meusdyBcs899+ijjz5Sly5d9MILL/iml5aWKj09XdHR0Ro+fHir59qyZUuD+w2Xy6UlS5a0+l82NCQqKkqLFi2S0+lU27ZtNWbMGG3cuFFerzco9imN5QiWMeJyuTR//nytXbtWmzdvVp8+fTRnzpwGx0QgxsgVV1yh3//+95o0aZLS0tJ07bXXym63+56vqanRo48+Ko/HowkTJrRKptOPraKiohrclnz11VcB3Z+cnvFUkarP4/EEbJ/SUL762+lAjpHzOX4OljFSH2XvAtu7d69Gjhyp4cOH66GHHgpolp07d+rXv/61fv/732v48OFau3at9uzZo2HDhikzM1Off/65HnnkkYBk27t3rwoLCyVJbdu2VXx8vJYuXao+ffooKipKYWFhGjx4sHbt2hWQfHl5edqyZYuGDRum559/XuvXr9cDDzyg8PBwXX/99ZKkESNG6OOPPw5Ivi5duqhfv37q1KmTLrnkEt1+++0qKCiQy+XyzeNyuepcphMINTU12r59e50vpgfLGNm8ebP69eunzp07q02bNkpNTdVnn30ml8ulO++8U+np6Tpy5IhGjx4dkHxlZWWKj4/XmjVrtGzZMrVp00Y9e/ZUjx49dN1110mSkpOTAzZGTomMjGzwc/fVV18FzXhp6DNXP3dJSUlAxsvhw4e1c+dOSZLNZlNSUpK+/PJLSfJ9/q699toGz8a0hsb2Gxs2bNDx48eVlpbmO7sybNgwlZWVtXrGL7/8Uu+++67vsTFGNptNXbp0CYp9SmM5gmWM7NixQz179tTll1+u0NBQ3XPPPfr444/VqVMnlZaWyuv1SgrcPqW6ulrXX3+9cnJy9Oabb6pr166KioqSJJWXl2v8+PHyeDxasmRJnRJ4odQ/tmpsG5ifnx+w/Un9jI1xOBwB2ac0lK+h7XSgxsj5Hj8Hyxg5QwC/L2hZAwcO9H0JOy4uzqxatSrQkUxRUZG5+eabTUFBQYPPb9u2LaA3aNmwYYNJTU011dXVprq62tx///1m1apVZsCAAaaoqMgYc/JL2AsXLgxYxlPefvtt8/jjj5vjx4+bfv36mb179xpjjFm9enXA3sNPP/3UJCQkmB9++MF3847XXnvNxMbGmv379xuPx2N+85vfmLy8vIDkO2XXrl1m5MiRvsfBNEY2bdpkhg4dasrLy01tba154oknzPPPP+97/uDBgwG9QUthYaEZOnSocbvd5sSJEyYhIcHs2LGjzo0eXnrpJfPoo48GJN+p7V5VVVWDn7tAj5fz2S4nJSWZHTt2GGOMyczMNH/+859bPd+XX35pBg4caH744QdTW1trMjIyzEsvvWQ8Ho8ZPny4WbRoUatlaijf6c6232jNG7SccipjYWGhiY2NNcePHzc1NTVm3LhxZs2aNaaoqCig+5RT+RrLESxj5OuvvzZxcXHG5XIZY4xZsmSJ76ZkDzzwgFm9erUxxpjFixebP/zhD62e7+jRoyYuLs6Ulpaa6upqM3r0aF+mSZMmmczMTOP1elslU0PHVo1tA0/XmvuTcx3/3Xvvvb4btFRWVrb6PqWhfI1tpwMxRpp6/BzIMdIYvrN3Aa1YsUIlJSV69dVXfT8lcNttt2nKlCmtnuXll19WdXV1ndPxI0eO1KhRo1o9S0Pi4uK0a9cu3XHHHQoLC1N8fLzuuOMOdejQQRMnTlR1dbV++tOfBvSyr/r+4z/+Q3PmzNEjjzwiY4w6d+6sZ555JiBZ+vTpo/Hjx2v06NFyu9269dZbNWrUKF155ZWaPHmyqqurFRcX1+rfpanv4MGDioyM9D0OpjHSv39/7d69W6mpqbLb7bruuuuUnp7e6jkaEx0drfj4eA0dOlRer1e//vWvdcMNN2jRokXKzMxUZWWlIiMjz7gtdGsLDw/X3Llzz/jchYSEBMV4Odtnbv78+crMzFRZWZl69eqlsWPHtnq+nj17Kj09XSNHjlRYWJhiYmJ0//33a/369dq9e7e8Xq/vrFXv3r0DdoYvmEVHRys9PV2jRo2Sx+NRfHy8kpOTJUmzZ88O+D6lW7duDeZo27ZtUIyRq666SlOmTNHYsWMVFhamHj16aPbs2ZKkrKwsZWRkaMmSJerWrZsWLFjQ6vk6duyohx56SCNGjJDH4/Hdnn/37t364IMPdPXVV/vODjmdTv35z3++YFkaO7ZqaBsYKE05/rvkkktafZ/SUL4hQ4Y0up1u7THS1OPnYBgj9YUY8+8f8AEAAAAAWAbf2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIIoewAAAABgQZQ9AAAAALAgyh4A4KLldrvVv39/jR8/vsWX7fV6NWHCBJWUlLT4susbN26cjh49KunkLcb/+c9/nvdry8rKNH78eFVVVV2oeACAixRlDwBw0Vq3bp2io6P1+eefa+/evS267FdeeUU33XSTunTp0qLLbciWLVua/dqIiAglJyfrj3/8YwsmAgBYAb+zBwC4aI0ZM0ZDhgzRnj175PF4fD/+vHTpUq1YsUI/+clPFBMTow8++EDr169XTU2N5s+fr+3bt8vr9epnP/uZMjMzFRERUWe5lZWVGjRokNasWaOOHTvqT3/6k7799lsVFxfL5XKpV69euvnmm5WTk6PvvvtO06ZNU3Jystxut+bOnautW7cqLCxM119/vaZPn66IiAjddtttGj58uLZu3arDhw9r2LBheuSRRzR9+nStXLlSPXv21NKlS5WWlqZbbrlFu3fv1tGjRzVs2DBNnTpV5eXlmj59ug4cOKDQ0FD16tVLs2fPVmhoqKqrq/WrX/1KOTk5rVJOAQAXB87sAQAuSl9//bU++eQTJSYm6o477lBubq6OHTumTZs2aeXKlVqxYoVWrlyp8vJy32uWLl2qsLAwrVy5UqtXr5bT6dT8+fPPWPa2bdt0xRVXqGPHjr5pO3fu1KJFi7Rq1Sp9+OGH2rt3r5YvX64nnnhCf/rTnyRJS5Ys0ZEjR5Sbm6vc3FzV1tbq2Wef9S2joqJCr7/+ut5880298sorOnjwoObMmSNJ+utf/6pu3bpJksLDw7Vy5Uq99dZbeuWVV3T48GGtW7dO5eXlys3N1YoVKyRJBw8e9M3fu3dvbdy4sYXfZQDAxcwW6AAAADTHG2+8oYEDB6pjx47q2LGjLrvsMmVnZ8vlcikxMVGXXnqpJCktLU3btm2TJG3YsEGlpaUqKCiQdPI7f507dz5j2fv27dPll19eZ9ott9yi9u3bS5KcTqcGDBggSbr88st1/PhxSdKHH36oqVOnym63Szp55vGhhx7yLeNXv/qVJKlr167q3LmzfvjhB0VFRZ3x309OTpYkORwOdenSRd9//71uuOEGLVy4UGPGjNEtt9yi++67Tz169PC95rLLLtM333zT1LcRAGBhlD0AwEWnoqJCubm5atOmjW677TZJJ29U8tprrykpKUmnf0MhLCzM9++1tbWaMWOG4uLiJEnl5eWqrq4+Y/khISGqra2tM61NmzZ1HttsZ+5Ca2trFRISUuex2+32PQ4PD6/z32jsmxSnL/vUfFFRUVq3bp0++ugjbdu2Tffff79mz57tW3+73V5nXQEA4DJOAMBFZ82aNerQoYM2bdqk9evXa/369Xr//fdVUVGhXr166b333lNpaakk+S55lKT+/ftr+fLlqqmpUW1trZ544gktWLDgjOVfccUVvkskm2LAgAF644035Ha7VVtbq+XLl+vWW2895+vCwsLk8XjOOs/rr7+u6dOnq3///po2bZr69++v3bt3+57/7rvvdMUVVzQ5MwDAuih7AICLzhtvvKH777+/zpmsSy+9VGPGjNFf/vIX3XPPPRoxYoRSU1NVWlqqtm3bSpIefPBBde/eXcOHD9eQIUNkjFFGRsYZy7/lllu0b98+nThxokm5Jk2apC5duuiOO+7Q4MGD5fF4NHPmzHO+LjExUWPGjNFXX33V6Dx33HGHvF6vhgwZ4luvMWPGSJJqamr06aef+s7yAQAgcTdOAIDF/POf/9Qnn3yisWPHSpJeffVVffbZZ3ruueeatJwXX3xRYWFheuCBBy5EzBa1cuVK7dmzR48//nigowAAgghn9gAAlnLFFVdox44dSk5OVkpKirZu3arp06c3eTnjxo3Ttm3b5HK5LkDKllNeXq61a9dq8uTJgY4CAAgynNkDAAAAAAvizB4AAAAAWBBlDwAAAAAsiLIHAAAAABZE2QMAAAAAC6LsAQAAAIAFUfYAAAAAwIL+P/nNmtGhMBqUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = df['Age'] # get Age array\n",
    "nr_bins = 1 + 3.322*math.log(len(a),2) # Number of bins according to Sturges rule\n",
    "sns.set(rc={'figure.figsize':(15,5)}) # set figure size\n",
    "\n",
    "# setting up the axis\n",
    "fig, ax = plt.subplots()\n",
    "ticks = [i for i in range(0,260,12)]\n",
    "ticks.pop(0)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xlim([0.0,250])\n",
    "\n",
    "sns.distplot(a, bins=round(nr_bins), kde=False, axlabel=\"Age (months)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cat is considered a kitten roughly until it reaches the age of 1 year old. The same goes for puppies. On the other hand, dogs and cats are considered Seniors roughly when they reach the age of 6 years. Of course, these are approximations, as the classification varies with the type of animal (cats or dogs), breed, size and many other factors.\n",
    "\n",
    "In this sense, we will consider these categories:\n",
    "* Baby - age 0-11 months => 0\n",
    "* Adult - age 12-71 months =>1\n",
    "* Senior - age 72-250 months =>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature - AgeGroup\n",
    "AgeGroup = []\n",
    "for i in df[\"Age\"]:\n",
    "    if i<12:\n",
    "        AgeGroup.append(0)\n",
    "    elif i<72:\n",
    "        AgeGroup.append(1)\n",
    "    else:\n",
    "        AgeGroup.append(2)\n",
    "\n",
    "df_processed2 = df_processed1.copy()\n",
    "df_processed2.drop(\"Age\", axis=1, inplace = True)\n",
    "df_processed2.insert(2,\"AgeGroup\",AgeGroup) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','AgeGroup', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative distribution of `AgeGroup` among `AdoptionSpeed` indicates that there seems to be no particular correlation between being younger and getting adopted earlier. Even without the dicretization we can observe the same phenomena: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.ylim(0, 260)\n",
    "sns.boxplot(data = df, x='AdoptionSpeed', y='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breed1 and Breed2\n",
    "\n",
    "According to the breeds feature labels, dogs breeds go from 1 to 240, plus 307, and cats breeds go from 241 to 306. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx1 = sns.catplot(x=\"Breed1\",data=df, kind='count',height=9, aspect=3)\n",
    "bx2 = sns.catplot(x=\"Breed2\",data=df, kind='count',height=9, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, and according to the breeds feature labels, we found some cats with dogs breeds assigned to them (15, 21, 25, 70, 114, 205, 218, 307).\n",
    "Therefore, and given the distribution of pets by breeds in which some breeds are poorly representated perhaps a good idea should be grouping pets by pure-race/mixed-race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature: Pure breed\n",
    "l3 =[]\n",
    "for i in range(len(df)):\n",
    "    if df['Breed1'][i]==307 or df['Breed2'][i]==307:\n",
    "        l3.append(0)\n",
    "    elif df['Breed1'][i]!=307 and df['Breed2'][i]==0:\n",
    "        l3.append(1)\n",
    "    elif df['Breed1'][i]==0 and df['Breed2'][i]!=307:\n",
    "        l3.append(1)\n",
    "    elif df['Breed1'][i]==df['Breed2'][i]:\n",
    "        l3.append(1)\n",
    "    else:\n",
    "        l3.append(0)\n",
    "        \n",
    "df_processed2.drop(\"Breed1\",axis=1,inplace=True)\n",
    "df_processed2.drop(\"Breed2\",axis=1,inplace=True) \n",
    "df_processed2.insert(3,'PureBreed',l3) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr_pairwise('AdoptionSpeed','PureBreed', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot and relative gain table we conclude that pure breed animals (1) tend to be adopted earlier, whereas mixed breed animals (0) are adopted later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantity\n",
    "\n",
    "Number of pets represented in profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = sns.catplot(x='Quantity', data=df, kind='count')\n",
    "(ax3.set_axis_labels(\"Quantity\", \"Number of Pets\"))\n",
    "print('There are {} profiles with a single pet'.format((list(df['Quantity'])).count(1)))\n",
    "print('There are {} profiles with multiple pets'.format(len(df['Quantity'])-list(list(df['Quantity'])).count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ste = cat_distr_pairwise('AdoptionSpeed','Quantity', df, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"inf\" values on the table indicate that there are no examples of a pet with `AdoptionSpeed = 0` for that feature instance. Therefore, all positive relative gains are 'infinite'.\n",
    "\n",
    "We can conclude that adds containing more than 5 pets could be more likely to be ignored, since those pets are adopted after a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fee\n",
    "\n",
    "After observing the fees' distribution we considered 4 categories: \n",
    "* Free => 0\n",
    "* Tens => 1\n",
    "* Hundreds => 2\n",
    "* Thousands => 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in df[\"Fee\"]:\n",
    "    if i==0:\n",
    "        f.append(0)\n",
    "    elif i<100:\n",
    "        f.append(1)\n",
    "    elif i<1000:\n",
    "        f.append(2)\n",
    "    else:\n",
    "        f.append(3)\n",
    "\n",
    "df_processed2.drop(\"Fee\",axis=1,inplace=True) \n",
    "df_processed2.insert(4,'Free',f) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fee = cat_distr_pairwise('AdoptionSpeed','Free', df_processed2, frel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that pets with fees in the order of the thousands are less likely to be adopted fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RescuerID\n",
    "\n",
    "In order to extract some meaning from the `RescuerID`, we decided to create a new feature `FrequentRescuer` which indicates whether it is frequent for rescuers to save and advertise pets. After visiting *www.PetFinder.my*, we noticed pet profiles include links to other profiles by the same rescuer. In this way, it is plausible that users, while browsing the website, will look at related profiles more often than profiles by different users, thereby influencing adoption rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5595 total rescuers in the dataset\n",
      "There are 3783 rescuers with only 1 webpage entry in the dataset\n",
      "There are 1812 rescuers with more than 1 webpage entry in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1a201e9f90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(df['RescuerID'].unique())\n",
    "y = list(df['RescuerID'])\n",
    "z = []\n",
    "t = {}\n",
    "for i in x:\n",
    "    z.append(y.count(i))\n",
    "\n",
    "t['Rescuer'] = x\n",
    "t['entries'] = z\n",
    "\n",
    "e = pd.DataFrame(t)\n",
    "print('There are {} total rescuers in the dataset'.format(len(x)))\n",
    "print('There are {} rescuers with only 1 webpage entry in the dataset'.format(z.count(1)))\n",
    "print('There are {} rescuers with more than 1 webpage entry in the dataset'.format(len(x)-(z.count(1))))\n",
    "ax11 = sns.catplot(x='entries', data=e, kind='count', height=5, aspect=3)\n",
    "(ax11.set_axis_labels(\"Web page entries\", \"Number of Rescuers\")\n",
    "    .set_titles(\"{col_name} {col_var}\")\n",
    "    .despine(left=True))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset, the number of rescuers with a single entry in the PetFinder webpage is greater than the number of rescuers who save and advertise more than 1 pet. This information could be useful on later anaylsis to discover whether the number of webpage profile entries associated with a rescuer has any effect in pet adoption/adoption speed.\n",
    "\n",
    "An important aspect of this analysis is that, given we have access to around ~10% of the global dataset, it is possible that many ID's described as non-frequent may be mislabeled (if other instances of the ID are present in the remaining ~90% of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEW FEATURE FREQUENTRESCUER\n",
    "\n",
    "lista2 = []\n",
    "y = list(df['RescuerID'])\n",
    "for i in df['RescuerID']:\n",
    "      if y.count(i)>1:\n",
    "          lista2.append(float(1))\n",
    "      else:\n",
    "          lista2.append(float(0))\n",
    "          \n",
    "df_processed1.insert((df.columns.get_loc(\"RescuerID\"))+1,'FrequentRescuer',lista2) ##INSERT IN DATAFRAME\n",
    "df_processed1.drop(\"RescuerID\", axis=1, inplace=True)\n",
    "\n",
    "df_processed2.insert((df.columns.get_loc(\"RescuerID\"))+1,'FrequentRescuer',lista2) ##INSERT IN DATAFRAME\n",
    "df_processed2.drop(\"RescuerID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VideoAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = sns.catplot(x='VideoAmt', data=df, kind='count')\n",
    "(ax2.set_axis_labels(\"Video Amount\", \"Number of Pets\"))\n",
    "print('There are {} profiles with 0 videos'.format((list(df['VideoAmt'])).count(0)))\n",
    "print('There are {} profiles with more than 0 videos'.format(len(df['VideoAmt'])-list(list(df['VideoAmt'])).count(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the distribution of pets, we will consider this feature as binary: has Video (1) or does not have Video (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasVideo=[]\n",
    "\n",
    "for v in df['VideoAmt']:\n",
    "    if v==0:\n",
    "        hasVideo.append(0)\n",
    "    else:\n",
    "        hasVideo.append(1)\n",
    "        \n",
    "df_processed2.drop(\"VideoAmt\", axis=1,inplace=True)\n",
    "df_processed2.insert(5,\"hasVideo\",hasVideo) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "In order to extract some meaning from the `Description`, we decided, as a first approach, to partition this continuous feature into discrete values.\n",
    "\n",
    "Since empty descriptions (`size=0`) probably have a direct influence in the adoption choice, it should be a category of its own. For that reason, we exclude empty descriptions from the discretization process.\n",
    "\n",
    "We consider that the discretization of the 'description sizes' based on the quantiles strategy is appropriate, since it is plausible to say that the ad writers define what a 'medium'-sized description is. In that sense, a 'medium'-sized description would have the average word count. Analogously, the smallest and largest descriptions would correspond to the first and third quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average descripton size: 62.953645034349364\n",
      "According to this discretization, the bin edges should be:\n",
      "[array([   0.,   28.,   65., 1257.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import statistics \n",
    "\n",
    "l=[]\n",
    "\n",
    "# List descriptions' lengths (i.e. number of char)\n",
    "for i in df['Description']:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        l.append(0)\n",
    "    else:\n",
    "        l.append(len(i.split()))\n",
    "\n",
    "mean = statistics.mean(l)\n",
    "print(\"The average descripton size:\" , mean)\n",
    "\n",
    "# Histogram\n",
    "a1 = np.asarray(l)\n",
    "nr_bins = 1 + 3.322*math.log(len(l),2) # Number of bins according to Sturges rule\n",
    "a1 = pd.Series(a1)\n",
    "a1.plot.hist(grid=True, bins = round(nr_bins), rwidth=0.9, color='#607c8e')\n",
    "plt.title('Description size distribution')\n",
    "plt.xlabel('Description size (# words)')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlim([0.0,1300])\n",
    "\n",
    "# Discretization by quantile strategy:\n",
    "a2 = np.asarray(l).reshape(-1,1) # Reshape data since we are working with just one feature\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3],encode='ordinal', strategy='quantile').fit(a2)\n",
    "decp = est.transform(a2)\n",
    "\n",
    "print(\"According to this discretization, the bin edges should be:\")\n",
    "print(est.bin_edges_) # how the data is distributed in the four bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, we present a new feature 'DescriptionSize' whose possible values include:\n",
    "* `Empty` for descriptions containing 0 words => 0\n",
    "* `Small` for descriptions containing 1-28 words => 1\n",
    "* `Medium` for descriptions containing 29-65 words => 2\n",
    "* `Large` for descriptions containing 66-1257 words => 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new feature 'Description size'\n",
    "d = []\n",
    "\n",
    "for i in df['Description']:\n",
    "    if type(i)!=str: # Some empty descriptions are type:float\n",
    "        d.append(0)\n",
    "    else:\n",
    "        a= len(i.split())\n",
    "        if a<29:\n",
    "            d.append(1)\n",
    "        elif a<66:\n",
    "            d.append(2)\n",
    "        else:\n",
    "            d.append(3)    \n",
    "            \n",
    "df_processed1.drop(\"Description\", axis=1, inplace=True)\n",
    "df_processed1.insert(6,\"DescriptionSize\",l) ##INSERT IN DATAFRAME\n",
    "\n",
    "df_processed2.drop(\"Description\", axis=1, inplace=True)\n",
    "df_processed2.insert(6,\"DescriptionSize\",d) ##INSERT IN DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other conclusions\n",
    "* Pets with maturity size `Small` (1) and `Extra Large`(4) are less likely to be in the adoption centre for a very long time (-45.0552% and -97.3772 of pets at `AdoptionSpeed = 4` relatively to `AdoptionSpeed = 1`, respectively). \n",
    "* Pets with long fur (3) very rarely stay at the adoption centre for a long time (-116.814% of pets at `AdoptionSpeed = 4` relatively to `AdoptionSpeed = 1`).\n",
    "* Sterilized pets tend to be adopted later (+82.13% of pets at `AdoptionSpeed = 4` relatively to `AdoptionSpeed = 1`).\n",
    "* Pets with serious injuries (`Health = 3`) are very more likely to be adopted after a long time, or not adopted at all (+182.091% of pets at `AdoptionSpeed = 4` relatively to `AdoptionSpeed = 1`). \n",
    "* No pets were adopted in the same day having the add not provide a description!\n",
    "* There was no clear evidence that the distribution of the features values among `AdoptionSpeed` classes was biased for features `Gender`, `Vaccinated`, `Dewormed`, `State`, `FrequentRescuer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Supervised Learning) - Predicting Adoption and Adoption Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our EDA we already preprocessed some of the features, for data visualization purposes. The result are two datasets:\n",
    "* **df_processed1**: which we will use to benchmark the models' performance without the discretization of features discussed earlier, since they can remove the fine grain information that might be beneficial to the learning proccess. Some data cleaning was done, namely in features `PetID`, `Name`, `RescuerID` and `DescriptionSize` (in words, instead of text `Description`).\n",
    "\n",
    "* **df_processed2**: which is the data set with the derived features and data cleaning. We will see if the dicretization will be helpful for the models or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features impact\n",
    "\n",
    "Now that we have preprocessed our features, one way to determine the impact of each one on prediction models is to apply a random forest. Based on that information, we will  discard some features that have low impact and are probably causing noise.\n",
    "\n",
    "Bellow we have a function that will apply a random forest model to any data set.\n",
    "Code obtained from: <https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e>\n",
    "\n",
    "Random forest algorithms seek to maximise impurity decreases from node to node in each tree. Features are considered more important the more they decrease impurity in datasets amongst the entire random tree population that was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df_x, df_y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=test_size, random_state=12)\n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train) \n",
    "    score = rf.score(X_test, y_test)\n",
    "    feature_importance = pd.DataFrame(rf.feature_importances_, index = df_x.columns, columns=['importance']).sort_values('importance',ascending=False).reset_index().rename(columns = {'index':'column'})\n",
    "    return score, feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original features importance (df_processed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.3687895965321774\n",
      "             column  importance\n",
      "0   DescriptionSize    0.157876\n",
      "1               Age    0.106214\n",
      "2          PhotoAmt    0.098852\n",
      "3            Color2    0.064265\n",
      "4            Breed1    0.063187\n",
      "5            Color1    0.060539\n",
      "6             State    0.049873\n",
      "7            Breed2    0.044285\n",
      "8            Gender    0.038926\n",
      "9         FurLength    0.035579\n",
      "10     MaturitySize    0.033582\n",
      "11         Quantity    0.033392\n",
      "12              Fee    0.032417\n",
      "13           Color3    0.030186\n",
      "14       Vaccinated    0.029492\n",
      "15       Sterilized    0.027633\n",
      "16         Dewormed    0.027467\n",
      "17  FrequentRescuer    0.021656\n",
      "18          hasName    0.016351\n",
      "19             Type    0.010763\n",
      "20         VideoAmt    0.009512\n",
      "21           Health    0.007952\n"
     ]
    }
   ],
   "source": [
    "score1, feature_importances1 = random_forest(\n",
    "    df_processed1[df_processed1.columns.difference(['AdoptionSpeed'])],\n",
    "    df_processed1['AdoptionSpeed'],\n",
    "    0.2)\n",
    "print(\"Score: \",score1)\n",
    "print(feature_importances1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our exploratory analysis, the feature `DescriptionSize` was expected to have high impact, since we found that no pets lacking a Description were adopted on the same day. Additionally, `hasName`, `Vaccinated`, `FrequentRescuer`, `Dewormed` were expected to have a low impact, which is concordant to the random forest results.\n",
    "\n",
    "On the other hand, our exploratory analysis defined that `Quantity` and `Fee` would be discriminatory features, whereas `Age` wouldn't. The random forest results show that those features' impact is not as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracted features importance (df_processed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.3567855951983995\n",
      "             column  importance\n",
      "0          PhotoAmt    0.154515\n",
      "1            Color2    0.091672\n",
      "2            Color1    0.090944\n",
      "3             State    0.077082\n",
      "4   DescriptionSize    0.068832\n",
      "5         FurLength    0.051298\n",
      "6      MaturitySize    0.047519\n",
      "7            Gender    0.046751\n",
      "8            Color3    0.045368\n",
      "9          Quantity    0.044773\n",
      "10         Dewormed    0.042706\n",
      "11       Vaccinated    0.038364\n",
      "12             Free    0.035534\n",
      "13       Sterilized    0.030739\n",
      "14         AgeGroup    0.026929\n",
      "15  FrequentRescuer    0.024596\n",
      "16          hasName    0.022905\n",
      "17        PureBreed    0.020036\n",
      "18             Type    0.016041\n",
      "19         hasVideo    0.012041\n",
      "20           Health    0.011355\n"
     ]
    }
   ],
   "source": [
    "score2, feature_importances2 = random_forest(\n",
    "    df_processed2[df_processed2.columns.difference(['AdoptionSpeed'])], \n",
    "    df_processed2['AdoptionSpeed'],\n",
    "    0.2)\n",
    "\n",
    "print(\"Score: \",score2) \n",
    "print(feature_importances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that, after the features' extraction, some features are actually contributing less to the model then they were before:\n",
    "* `DescriptionSize` in bins ( vs `DescriptionSize` in number of words)\n",
    "* `AgeGroup` ( vs `Age`)\n",
    "* `PureBreed` ( vs `Breed1`, `Breed2`)\n",
    "\n",
    "We will go back to the original features in respect to the classification analysis.\n",
    "Some features are doing slightly better/did not get worse so we will keep the changes:\n",
    "* `hasVideo` (`VideoAmt`)\n",
    "* `Free` (`Fee`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY CHANGES TO DATASET - REVERT TO ORIGINAL FEATURES\n",
    "#Description\n",
    "df_processed2.drop(\"DescriptionSize\", axis=1, inplace=True)\n",
    "df_processed2.insert(6,\"DescriptionSize\",df_processed1['DescriptionSize'])\n",
    "\n",
    "#AgeGroup\n",
    "df_processed2.drop(\"AgeGroup\", axis=1, inplace = True)\n",
    "df_processed2.insert(2,\"Age\",df_processed1['Age'])\n",
    "\n",
    "#PureBreed\n",
    "df_processed2.drop(\"PureBreed\", axis=1, inplace=True)\n",
    "df_processed2.insert(6,\"Breed1\",df_processed1['Breed1'])\n",
    "df_processed2.insert(6,\"Breed2\",df_processed1['Breed2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imbalance\n",
    "\n",
    "As we explained in the beggining there is a clear imbalance in the number of examples:\n",
    "- Binary classification: the number of examples of `AdoptionSpeed < 4` (*Adopted*) is much greater than the number of examples for `AdoptionSpeed = 4` (*Not Adopted*).\n",
    "- Multiclass classification: the number of examples of `AdoptionSpeed = 0` is much smaller than the rest of the target classes.\n",
    "\n",
    "Since we are working with such a small dataset, we cannot spare any examples, and we will resort to random oversampling to balance our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification - Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADAPT TARGET COLUMN FOR BINARY CLASSIFICATION\n",
    "df_processed2_b = df_processed2.copy()\n",
    "df_processed2_b = df_processed2_b.rename(columns={'AdoptionSpeed': 'Adoption'})\n",
    "df_processed2_b = df_processed2_b.replace({'Adoption':[0,2,3]},1)\n",
    "df_processed2_b = df_processed2_b.replace({'Adoption':4},0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM OVERSAMPLING\n",
    "ros_b = RandomOverSampler(sampling_strategy='minority',random_state=42) #create oversampling class\n",
    "X_ros_b, y_ros_b = ros_b.fit_resample(df_processed2_b.iloc[:,:-1], df_processed2_b['Adoption']) #resample the oversampled dataset\n",
    "\n",
    "# y_ros_b is a np array in some versions and a pd dataframe/series in others \n",
    "# An object-type check must be applied in order to further proccess the data\n",
    "\n",
    "if ( isinstance(y_ros_b, pd.DataFrame) or isinstance(y_ros_b, pd.Series) ):\n",
    "    df_processed2_b_balanced = X_ros_b.join(y_ros_b)\n",
    "    \n",
    "else:\n",
    "    y_ros_b.shape = (21592,1) #reshape array for concatenation\n",
    "    np_processed2_b_balanced = np.concatenate((X_ros_b, y_ros_b), axis=1) #save new data\n",
    "    df_processed2_b_balanced = pd.DataFrame(data=np_processed2_b_balanced, columns=df_processed2_b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x=\"Adoption\",data=df_processed2_b_balanced, kind='count')\n",
    "(ax.set_axis_labels(\"Adoption\", \"Number of Pets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the oversampling was successful because we now have the same number of examples for adopted and not adopted pets, with a total of 21592 examples.\n",
    "\n",
    "We will be using `df_processed2_b_balanced` as the **balanced, binary task general dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass classification - Random Over-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the oversampling was successful because we now have the same number of examples for all `AdoptionSpeed`, with a total of 20985 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM OVERSAMPLING\n",
    "df_processed2_m = df_processed2.copy()\n",
    "ros_m = RandomOverSampler(random_state=42)\n",
    "X_ros_m, y_ros_m = ros_m.fit_resample(df_processed2_m.iloc[:,:-1], df_processed2_m['AdoptionSpeed'])\n",
    "\n",
    "# y_ros_b is a np array in some versions and a pd dataframe in others. \n",
    "# An object-type check must be applied in order to further proccess the data\n",
    "\n",
    "if ( isinstance(y_ros_b, pd.DataFrame) or isinstance(y_ros_b, pd.Series) ):\n",
    "    df_processed2_m_balanced = X_ros_m.join(y_ros_m)\n",
    "    \n",
    "else:\n",
    "    y_ros_m.shape = (20985,1) #reshape array for concatenation\n",
    "    np_processed2_m_balanced = np.concatenate((X_ros_m, y_ros_m), axis=1) #save new data\n",
    "    df_processed2_m_balanced = pd.DataFrame(data=np_processed2_m_balanced, columns=df_processed2_m.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.catplot(x=\"AdoptionSpeed\",data=df_processed2_m_balanced, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dogs and Cats - preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOGS BINARY CLASSIFICATION\n",
    "df_processed2_b_balanced_dogs = df_processed2_b_balanced.copy()\n",
    "df_processed2_b_balanced_dogs = df_processed2_b_balanced_dogs[df_processed2_b_balanced_dogs['Type']==1]\n",
    "\n",
    "# DOGS MULTICLASS CLASSIFICATION\n",
    "df_processed2_m_balanced_dogs = df_processed2_m_balanced.copy()\n",
    "df_processed2_m_balanced_dogs = df_processed2_m_balanced_dogs[df_processed2_m_balanced_dogs['Type']==1]\n",
    "\n",
    "# CATS BINARY CLASSIFICATION\n",
    "df_processed2_b_balanced_cats = df_processed2_b_balanced.copy()\n",
    "df_processed2_b_balanced_cats = df_processed2_b_balanced_cats[df_processed2_b_balanced_cats['Type']==2]\n",
    "\n",
    "# CATS MULTICLASS CLASSIFICATION\n",
    "df_processed2_m_balanced_cats = df_processed2_m_balanced.copy()\n",
    "df_processed2_m_balanced_cats = df_processed2_m_balanced_cats[df_processed2_m_balanced_cats['Type']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data encoding is a necessary step for categorical features. Our machine learning algorithms must receive numerical inputs, and as such, data organised in categories must be converted appropriately. We observe two distinct types of categorical features in our dataset:\n",
    "\n",
    "1) ordinal categorical data, that is, data organised in classes which have a natural order to them;\n",
    "\n",
    "2) nominal categorical data, that is, data organised in classes which are distinct and unordered.\n",
    "\n",
    "Of the first kind, we observe features such as `MaturitySize`, `FurLength` and `Health`. These benefit from label encoding, also known as ordinal encoding, which converts each class to a numerical value that preserves the order in the category. However, the existence of a default value `0` for unspecified fields makes analysis of these features easier if considering them nominal data.\n",
    "\n",
    "The remaining categorical features fit the second type. For these, one hot encoding is a good option. With this method, each class in the category becomes its own binary feature (it either exists or it doesn't in each data entry), therefore eliminating any underlying assumptions of order or distance between classes. This method tends to lose usefulness in cases of high cardinality features; tree-based models are more prone to overfit, as nodes will split in many possible values for each class in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function allows the encoding of the features of a given dataset\n",
    "# Inputs: \n",
    "  # df: the dataframe we want to enconde\n",
    "  # enc_features: list of features we want to encode\n",
    "  # nonenc_features: list of features we don't want to encode\n",
    "# Output: encoded dataset\n",
    "\n",
    "def encode(df, enc_features, nonenc_features, binary):\n",
    "    encoder = OneHotEncoder()\n",
    "    df_encoded = encoder.fit_transform(df[enc_features]).toarray()\n",
    "    column_name = encoder.get_feature_names(enc_features)\n",
    "    df_result =  pd.DataFrame(df_encoded, columns= column_name)\n",
    "    \n",
    "    # INSERT THE PETID AS INDEX\n",
    "    df_result.insert(0,'PetID',df.index.tolist())\n",
    "    df_result.set_index(\"PetID\", inplace=True) # change index to PetId\n",
    "    \n",
    "    # INSERT THE NON ENCODED FEATURES IN THE DATAFRAME AGAIN\n",
    "    count=2\n",
    "    for i in nonenc_features:\n",
    "        df_result.insert(count,i,df[i]) \n",
    "        count+=1\n",
    "        \n",
    "    # INSERT THE TARGET CLASS\n",
    "    if binary:\n",
    "        df_result.insert((len(df_result.columns)),'Adoption',df['Adoption']) ## Adoption (binary)\n",
    "    else:\n",
    "        df_result.insert((len(df_result.columns)),'AdoptionSpeed',df['AdoptionSpeed']) ## AdoptionSpeed\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/air/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### ENCODING FEATURES\n",
    "\n",
    "#df_processed1\n",
    "enc_features1 = ['Type','Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State']\n",
    "nenc_features1 = ['hasName','Age','DescriptionSize','Quantity','Fee','FrequentRescuer','VideoAmt','PhotoAmt']\n",
    "df_processed1_encoded = encode(df_processed1, enc_features1, nenc_features1, False)\n",
    "df_processed1_encoded.to_csv(r'C:\\Users\\david\\Documents\\GitHub\\Machine-Learning-2019\\df_processed1_m_encoded.csv', index_label='PetID')\n",
    "\n",
    "#df_processed2_b_balanced\n",
    "nenc_features2 = ['hasName','Age','DescriptionSize','Quantity','Free','FrequentRescuer','hasVideo','PhotoAmt']\n",
    "df_processed2_b_balanced_encoded = encode(df_processed2_b_balanced, enc_features1, nenc_features2, True)\n",
    "df_processed2_b_balanced_encoded.to_csv(r'C:\\Users\\david\\Documents\\GitHub\\Machine-Learning-2019\\df_processed2_b_balanced_encoded.csv', index_label='PetID')\n",
    "\n",
    "#df_processed2_m_balanced\n",
    "df_processed2_m_balanced_encoded = encode(df_processed2_m_balanced, enc_features1, nenc_features2, False)\n",
    "df_processed2_m_balanced_encoded.to_csv(r'C:\\Users\\david\\Documents\\GitHub\\Machine-Learning-2019\\df_processed2_m_balanced_encoded.csv', index_label='PetID')\n",
    "\n",
    "#df_processed2_b_balanced_dogs\n",
    "enc_features2 = ['Breed1','Breed2','Gender','Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Sterilized','Health','State']\n",
    "df_processed2_b_balanced_dogs_encoded = encode(df_processed2_b_balanced_dogs, enc_features2, nenc_features2, True)\n",
    "\n",
    "#df_processed2_b_balanced_cats\n",
    "df_processed2_b_balanced_cats_encoded = encode(df_processed2_b_balanced_cats, enc_features2, nenc_features2, True)\n",
    "\n",
    "#df_processed2_m_balanced_dogs\n",
    "df_processed2_m_balanced_dogs_encoded = encode(df_processed2_m_balanced_dogs, enc_features2, nenc_features2, False)\n",
    "\n",
    "#df_processed2_m_balanced_cats\n",
    "df_processed2_m_balanced_cats_encoded = encode(df_processed2_m_balanced_cats, enc_features2, nenc_features2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing: final dataset\n",
    "We have the following dataframes to feed the classifiers in the following phase:\n",
    "* Binary task: `df_processed2_b_balanced_encoded`\n",
    "* Multiclass task: `df_processed2_m_balanced_encoded`\n",
    "* Dogs binary task: `df_processed2_b_dogs_encoded`\n",
    "* Dogs multiclass task: `df_processed2_m_dogs_encoded`\n",
    "* Cats binary task: `df_processed2_b_cats_encoded`\n",
    "* Cats multiclass task: `df_processed2_m_cats_encoded`\n",
    "\n",
    "Remember the (non-encoded) features chosen for these datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'hasName', 'Age', 'Free', 'hasVideo', 'DescriptionSize', 'Breed2', 'Breed1', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'State', 'FrequentRescuer', 'PhotoAmt', 'Adoption']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_processed2_b_balanced.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a framework for printing confusion matrices side by side\n",
    "# X for some informative string\n",
    "# y_train for the training set targets\n",
    "# y_train_predict for the target predictions by the model\n",
    "# y_test for the test set targets \n",
    "# y_test_predict for the test predictions by the model\n",
    "\n",
    "def confusion (X,y_train,y_train_predict,y_test,y_test_predict):\n",
    "    print('{}'.format(X))\n",
    "    \n",
    "    cm_train = confusion_matrix(y_train, y_train_predict)\n",
    "    cm_test = confusion_matrix(y_test, y_test_predict)\n",
    "    \n",
    "    y = np.unique(y_train)\n",
    "    z = np.unique(y_test)\n",
    "    \n",
    "    f, ax = plt.subplots(1,2) # defines two matrix plots, one for the training set and the other for the test set\n",
    "    sns.heatmap(cm_train.T, square=True, annot = True, fmt='d', cbar=False,\n",
    "                xticklabels=(y),\n",
    "                yticklabels=(y),\n",
    "                ax=ax[0]) # first plot\n",
    "    ax[0].set_xlabel('True class')\n",
    "    ax[0].set_ylabel('Predicted class')\n",
    "    ax[0].set_title('Confusion Matrix - Training Set')\n",
    "\n",
    "    sns.heatmap(cm_test.T, square=True, annot = True, fmt='d', cbar=False,\n",
    "                xticklabels=(z),\n",
    "                yticklabels=(z),\n",
    "                ax=ax[1]) # second plot\n",
    "    ax[1].set_xlabel('True class')\n",
    "    ax[1].set_ylabel('Predicted class')\n",
    "    ax[1].set_title('Confusion Matrix - Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a framework for model fitting, scoring and target predictions\n",
    "# takes xtrain, ytrain, xtest and ytest as arguments\n",
    "# the arguments xtrain, ytrain, xtest and ytest come from splitting the dataset into training and test sets\n",
    "# takes the classifier (model) as argument \n",
    "# prints classification reports for both training and test sets\n",
    "# returns predicted targets for both training and test sets\n",
    "# returns fitting scores (accuracy) for both training and test sets\n",
    "\n",
    "def model (intro,xtrain,ytrain,xtest,ytest,md):\n",
    "    #print (\"{}\\n\".format(intro))\n",
    "    #md = model.fit(xtrain,ytrain)\n",
    "    print(\"Accuracy on training set:\\n\")\n",
    "    trainscore = md.score(xtrain, ytrain)\n",
    "    print(\"{}\\n\".format(trainscore))\n",
    "    ytrainp = md.predict(xtrain)\n",
    "    print('Classification report (training):')\n",
    "    print(classification_report(ytrain,ytrainp))\n",
    "    print(\"Accuracy on test set:\\n\") \n",
    "    testscore = md.score(xtest, ytest)\n",
    "    print(\"{}\\n\".format(testscore))\n",
    "    ytestp = md.predict(xtest)\n",
    "    print('Classification report (test):')\n",
    "    print(classification_report(ytest,ytestp))\n",
    "    return ytrainp, ytestp, trainscore, testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates examples from targets and optionally splits it into training and testing\n",
    "def separate_split(df,split):\n",
    "    nc = df.shape[1]\n",
    "    matrix = df.values # Convert dataframe to darray\n",
    "    examples = matrix [:, 0:nc-1] # get features \n",
    "    target = matrix [:, nc-1] # get class (last columns)           \n",
    "    fnames = df.columns.values[0:nc-1] #get features names\n",
    "    tname = df.columns.values[nc-1] #get target name\n",
    "    examples = examples.astype(float)\n",
    "    target = target.astype(float)\n",
    "    if not split:\n",
    "        return examples, target, fnames, tname\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(examples, target, random_state=0)\n",
    "        print(\"Number of examples and features for the training dataset: \", X_train.shape)\n",
    "        print(\"Number of examples and features for the test dataset: \", X_test.shape)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conducts k-fold cross-validation for a certain model\n",
    "def crossvalidation(model,examples,target,classes):\n",
    "    \n",
    "    # 5-fold cross validation to return estimators and their individual scores\n",
    "    scores_list = cross_validate(model,examples,target,cv=5,return_train_score=True,return_estimator=True)\n",
    "    train_test_df = pd.DataFrame({'Training score': scores_list['train_score'],\n",
    "                                  'Test score': scores_list['test_score']},index=list(range(5)))\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    train_test_df.plot(x = 'Training score',\n",
    "                       y = 'Test score',\n",
    "                       kind = 'scatter',\n",
    "                       ax = ax[0])\n",
    "    \n",
    "    for train, test in train_test_df.iterrows():\n",
    "        ax[0].annotate(train, test)     \n",
    "    ax[0].set_title('Cross-Validation Estimator Scores')\n",
    "    \n",
    "    # prediction for confusion matrix\n",
    "    target_pred = cross_val_predict(model, examples, target, cv=5)\n",
    "    conf_mat = confusion_matrix(target, target_pred,labels=classes)\n",
    "    print('Test set results:')\n",
    "    print(classification_report(target, target_pred))\n",
    "    \n",
    "    # scores for the 5 estimators\n",
    "    scores = cross_val_score(model, examples, target, cv=5)\n",
    "    print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    # confusion matrix heatmap\n",
    "    sns.heatmap(conf_mat.T, square=True, annot=True, fmt='d', cbar=False, cmap=\"Blues\", ax=ax[1])\n",
    "    ax[1].set_xlabel('True class')\n",
    "    ax[1].set_ylabel('Predicted class')\n",
    "    ax[1].set_title('Confusion Matrix - Cross-Validation')\n",
    "    return target_pred, conf_mat, scores, scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Benchmark\n",
    "Before going into training the classifiers with our altered datasets, we want to perform a benchmark of the original dataset's performance in the models (`df_processed1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples and features for the training dataset:  (11244, 377)\n",
      "Number of examples and features for the test dataset:  (3749, 377)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = separate_split(df_processed1_encoded,True)\n",
    "examples_binary, target_binary, fnames_binary, tname_binary = separate_split(df_processed1_encoded,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.1 Predicting Adoption (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary task, `AdoptionSpeed` has to be converted into a binary target class (`0` for profiles with `AdoptionSpeed = 4` and `1` for profiles with `AdoptionSpeed < 4`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts an array of multiclass targets into binary classes\n",
    "def binarize(table_y):\n",
    "    for i in range(len(table_y)):\n",
    "        if table_y[i]<4:\n",
    "            table_y[i]=1\n",
    "        else:\n",
    "            table_y[i]=0\n",
    "    return table_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives cases in the dataset is: 10796\n",
      "Number of negative cases in the dataset is: 4197\n",
      "Ratio of positive to negative cases in the dataset: 2.5723135573028353\n"
     ]
    }
   ],
   "source": [
    "y_train_binary = binarize(y_train)\n",
    "y_test_binary = binarize(y_test)\n",
    "target_binary = binarize(target_binary)\n",
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_binary == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_binary == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_binary == 1))/(np.count_nonzero(target_binary == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of machine learning algorithms will be used to solve the task, as a way to see which will be the most appropriate. Model hyperparameters (if applicable) can be determined manually or via automatic methods, such as grid search.\n",
    "\n",
    "In order to optimise the model, the grid search method does an exhaustive assessment of best hyperparameters for the estimator. The grid search will go through all possible hyperparameter combinations and evaluate each model using a few metrics for scoring.\n",
    "\n",
    "5-fold cross-validation is the default model evaluation in this case. The training data is split in 5 equally-sized subsets (hence, the \"5-fold\"), and the model will be trained 5 times, each time leaving a different subset out, to be a test set. The performance of the model is the average of the performance over all (5) different test sets. Below, there is an image explaining the process.\n",
    "\n",
    "<img src=https://scikit-learn.org/stable/_images/grid_search_cross_validation.png width=\"500\">\n",
    "\n",
    "Classification reports can be broken down in 4 columns of precision, recall, score and support:\n",
    "\n",
    "* 1 row for each target class;\n",
    "* 1 row for the overall accuracy.\n",
    "\n",
    "Since the scoring is F1 macro:\n",
    "* 1 row for macro averages;\n",
    "* 1 row for weighted averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the pipeline consists of:\n",
    "\n",
    "1) Initialise an estimator;\n",
    "\n",
    "2) Fit the training data (train the model) to the estimator and test it (via test split), using k-fold cross-validation;\n",
    "\n",
    "3) Score model using various metrics and discuss results.\n",
    "\n",
    "In the case of grid search-applicable algorithms, k-fold cross validation is conducted to select the best estimator, and an additional k-fold cross-validation step is done to isolate its scores and results for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance-based Models - K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function is a pipeline for training and testing knn models\n",
    "# on binary or multiclass analysis\n",
    "# args:\n",
    "# binary = (boolean) whether the analysis is binary or not\n",
    "\n",
    "def knn(examples,target,binary):\n",
    "    # Initialising the estimator\n",
    "    knn = neighbors.KNeighborsClassifier() # 5 neighbours by default\n",
    "    \n",
    "    #Grid search (hyperparameter tuning) and k-fold cross-validation fitting/scoring\n",
    "    # Defining and applying a grid search cross validation to find the best hyperparameters for the knn estimator \n",
    "    # adequate metric, adequate p for the minkowski metric, adequate number of neighbours and weights\n",
    "    if binary:\n",
    "        knn_p = {'metric': ['minkowski','chebyshev'],\n",
    "                          'p': [1,2,3,4,5],\n",
    "                          'n_neighbors': [2,3,4,5,6,7], # even and odd number of neighbours\n",
    "                          'weights': ['uniform','distance']}\n",
    "    else:\n",
    "        knn_p = {'metric': ['minkowski','chebyshev'],\n",
    "                      'p': [1,2,3,4,5],\n",
    "                      'n_neighbors': [2,4,6,8,10,20], \n",
    "                      'weights': ['uniform','distance']}\n",
    "    \n",
    "    # There are 2 * 5 * 6 * 2 = 120 different combinations of hyperparameters, meaning that the grid search \n",
    "    # will create all these different versions of the model, which are then fit to the training data. \n",
    "    # Since each model goes through 5-fold cross-validation, there are 120 * 5 = 600 fits in total.\n",
    "    \n",
    "    # The scoring metric for the grid searh in the benchmark task will be the score of the estimator (runs slow)\n",
    "    knn_grid = GridSearchCV(knn, # creates all 120 versions of the KNN model\n",
    "                            knn_p, \n",
    "                            scoring='f1_macro',\n",
    "                            cv=5,\n",
    "                            verbose=10,\n",
    "                            n_jobs = 1) # CHANGE TO n_jobs = -1 TO USE MAXIMUM PARALLEL PROCESSES (INCREASE SPEED)\n",
    "    knn_grid.fit(examples,target) # 5-fold cross-validation fitting (120 * 5 fits) for KNN models\n",
    "    \n",
    "    # Picking and revalidating the best estimator\n",
    "    knn_best = knn_grid.best_estimator_ # assigning the parameters to the KNN estimator\n",
    "    print('Best estimator:\\n\\n{}'.format(knn_best))\n",
    "    \n",
    "    # Print scores\n",
    "    if binary:\n",
    "        a = [0,1]\n",
    "    else:\n",
    "        a = [0,1,2,3,4]\n",
    "        \n",
    "    (y_pred_knn, \n",
    "     conf_mat_knn, \n",
    "     knn_scores, \n",
    "     knn_scores_list) = crossvalidation(knn_best,\n",
    "                                        examples,\n",
    "                                        target,\n",
    "                                        a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=uniform, score=0.586, total=   4.0s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=uniform, score=0.587, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=uniform, score=0.596, total=   4.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=uniform, score=0.589, total=   4.5s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   16.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=uniform, score=0.596, total=   4.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=distance ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   20.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=distance, score=0.608, total=   4.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=distance ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   25.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=distance, score=0.591, total=   4.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=distance ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   29.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=distance, score=0.605, total=   4.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=distance ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   33.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=distance, score=0.605, total=   4.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=1, weights=distance ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   37.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=2, p=1, weights=distance, score=0.612, total=   4.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=uniform, score=0.582, total=   3.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=uniform, score=0.570, total=   2.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=uniform, score=0.578, total=   3.0s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=uniform, score=0.574, total=   2.4s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=uniform, score=0.574, total=   2.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=distance, score=0.596, total=   2.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=distance, score=0.578, total=   2.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=distance, score=0.586, total=   2.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=distance, score=0.585, total=   2.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=2, weights=distance, score=0.590, total=   2.4s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=uniform, score=0.579, total=   7.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=uniform, score=0.569, total=   6.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=uniform, score=0.573, total=   6.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=uniform, score=0.560, total=   6.7s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=uniform, score=0.578, total=   6.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=distance, score=0.584, total=   6.6s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=distance, score=0.568, total=   6.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=distance, score=0.586, total=   6.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=distance, score=0.580, total=   6.9s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=3, weights=distance, score=0.586, total=   6.9s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=uniform, score=0.573, total=   6.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=uniform, score=0.565, total=   5.6s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=uniform, score=0.571, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=uniform, score=0.563, total=   5.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=uniform, score=0.575, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=distance, score=0.574, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=distance, score=0.566, total=   5.4s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=distance, score=0.581, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=distance, score=0.579, total=   4.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=4, weights=distance, score=0.587, total=   5.4s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=uniform, score=0.572, total=   5.3s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=uniform, score=0.566, total=   5.0s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=uniform, score=0.570, total=   4.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=uniform, score=0.563, total=   4.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=uniform, score=0.575, total=   5.0s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=distance, score=0.573, total=   5.6s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=distance, score=0.566, total=   4.8s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=distance, score=0.580, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=distance, score=0.579, total=   5.0s\n",
      "[CV] metric=minkowski, n_neighbors=2, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=2, p=5, weights=distance, score=0.585, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=uniform, score=0.610, total=   4.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=uniform, score=0.588, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=uniform, score=0.592, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=uniform, score=0.596, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=uniform, score=0.595, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=distance, score=0.617, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=distance, score=0.594, total=   3.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=distance, score=0.600, total=   4.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=distance, score=0.603, total=   3.8s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=1, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=1, weights=distance, score=0.604, total=   3.8s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=uniform, score=0.598, total=   2.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=uniform ...........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=uniform, score=0.580, total=   2.6s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=uniform, score=0.591, total=   2.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=uniform, score=0.583, total=   2.6s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=uniform, score=0.581, total=   3.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=distance, score=0.597, total=   2.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=distance, score=0.583, total=   2.4s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=distance, score=0.594, total=   2.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=distance, score=0.585, total=   2.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=2, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=2, weights=distance, score=0.582, total=   2.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=uniform, score=0.585, total=   7.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=uniform, score=0.573, total=   6.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=uniform, score=0.584, total=   6.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=uniform, score=0.577, total=   6.4s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=uniform, score=0.583, total=   7.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=distance, score=0.584, total=   7.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=distance, score=0.574, total=   6.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=distance, score=0.585, total=   7.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=distance, score=0.580, total=   6.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=3, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=3, weights=distance, score=0.584, total=   7.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=uniform, score=0.575, total=   6.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=uniform, score=0.569, total=   6.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=uniform, score=0.581, total=   6.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=uniform, score=0.577, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=uniform, score=0.580, total=   6.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=distance, score=0.573, total=   5.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=distance, score=0.569, total=   5.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=distance, score=0.582, total=   5.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=distance, score=0.580, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=4, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=4, weights=distance, score=0.582, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=uniform, score=0.574, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=uniform, score=0.571, total=   5.2s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=uniform, score=0.581, total=   5.5s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=uniform, score=0.577, total=   5.6s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=uniform, score=0.579, total=   5.1s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=distance, score=0.572, total=   5.7s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=distance, score=0.571, total=   6.3s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=distance, score=0.580, total=   6.0s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=distance, score=0.580, total=   5.9s\n",
      "[CV] metric=minkowski, n_neighbors=3, p=5, weights=distance ..........\n",
      "[CV]  metric=minkowski, n_neighbors=3, p=5, weights=distance, score=0.582, total=   5.9s\n",
      "[CV] metric=minkowski, n_neighbors=4, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=4, p=1, weights=uniform, score=0.620, total=   5.0s\n",
      "[CV] metric=minkowski, n_neighbors=4, p=1, weights=uniform ...........\n",
      "[CV]  metric=minkowski, n_neighbors=4, p=1, weights=uniform, score=0.603, total=   4.8s\n",
      "[CV] metric=minkowski, n_neighbors=4, p=1, weights=uniform ...........\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0906db19689c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_binary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_binary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-c250e393d5d0>\u001b[0m in \u001b[0;36mknn\u001b[0;34m(examples, target, binary)\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             n_jobs = 1) # CHANGE TO n_jobs = -1 TO USE MAXIMUM PARALLEL PROCESSES (INCREASE SPEED)\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 5-fold cross-validation fitting (120 * 5 fits) for KNN models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Picking and revalidating the best estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \"\"\"\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 delayed_query(\n\u001b[1;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             )\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn(examples_binary,target_binary,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the grid search algorithm, the best hyperparameters found were the `metric = 'minkowski'` with `p = 1`, meaning distance is measured as the Manhattan distance, with 4 neighbours. Odd numbers are recommended in KNN algorithms to ensure easy majorities in neighbour classes, but it seems an even number scored highest in our selection of numbers. `weights = 'uniform'` attributes equal weight in determining class prediction to every considered neighbour.\n",
    "\n",
    "It's clear that the algorithm is weak in predicting `Adoption=0`, suggesting the imbalance in the dataset is compromising analysis and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probabilistic Models - Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naïve Bayes algorithm has many different variations, such as:\n",
    "\n",
    "1) *Gaussian*, best used in continuous numerical datasets (presumes a normal distribution of values);\n",
    "    \n",
    "2) *Multinomial*, when features represent frequency counts/number of occurrences;\n",
    "    \n",
    "3) *Bernoulli*, for datasets with binary categories;\n",
    "    \n",
    "4) *Complement*, which is designed for imbalanced datasets.\n",
    "\n",
    "An important aspect to consider in Naïve Bayes models is the underlying assumption that all features are independent from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function is a pipeline for training and testing naive bayes Bernoulli models\n",
    "# on binary or multiclass analysis\n",
    "# args:\n",
    "# binary = (boolean) whether the analysis is binary or not\n",
    "\n",
    "def bernoulli(examples,target,binary):\n",
    "    \n",
    "    # Initialising the estimator\n",
    "    bnb = BernoulliNB()\n",
    "    \n",
    "    # Print scores\n",
    "    if binary:\n",
    "        a = [0,1]\n",
    "    else:\n",
    "        a = [0,1,2,3,4]\n",
    "    \n",
    "    # K-fold cross-validation fitting/scoring\n",
    "    (y_pred_bnb, \n",
    "     conf_mat_bnb, \n",
    "     bnb_scores, \n",
    "     bnb_scores_list) = crossvalidation(bnb,\n",
    "                                        examples,\n",
    "                                        target,\n",
    "                                        a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli(examples_binary,target_binary,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark tests of Bernoulli Naïve Bayes reveal the following points: prediction of `Adoption=0` is very weak in comparison to `Adoption=1`, most likely due to the imbalance in the used dataset (F1 score of 0.45 and a clearly high number of false `Adoption=1` predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tree Models - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a pipeline for training and testing tree models\n",
    "# on binary or multiclass analysis\n",
    "# args:\n",
    "# binary = (boolean) whether the analysis is binary or not\n",
    "# tree_vis = (boolean) whether we want to output a visual representation of the tree\n",
    "\n",
    "def decision_tree (examples, target, binary, tree_vis, fnames):\n",
    "    \n",
    "    # Initialising the estimator\n",
    "    dec_tree = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    # Grid search (hyperparameter tuning) and k-fold cross-validation fitting/scoring\n",
    "    # The grid search will test the Gini index criterion versus the information gain criterion.\n",
    "    if binary:\n",
    "        dec_tree_p = {'criterion': ['gini','entropy']}\n",
    "    else:\n",
    "        dec_tree_p  ={'class_weight':[None,'balanced'],\n",
    "                             'criterion':['gini','entropy'],\n",
    "                             'max_features':[None,'auto','log2'],\n",
    "                             'min_samples_leaf':[1,2,3,4,5,6],\n",
    "                             'min_samples_split':[2,3,4,5]}\n",
    "\n",
    "    dec_tree_grid = GridSearchCV(dec_tree, \n",
    "                                dec_tree_p, \n",
    "                                scoring='f1_macro',\n",
    "                                cv=5,\n",
    "                                n_jobs = 1) # creates all 2 versions of the decision tree model\n",
    "\n",
    "    dec_tree_grid.fit(examples,target)\n",
    "\n",
    "    # Picking and revalidating the best estimator\n",
    "    # assigning the parameters to the decision tree estimator\n",
    "    dec_tree_best = dec_tree_grid.best_estimator_ \n",
    "    print('Best estimator:\\n\\n{}'.format(dec_tree_best))\n",
    "\n",
    "    # Print scores\n",
    "    if binary:\n",
    "        a = [0,1]\n",
    "    else:\n",
    "        a = [0,1,2,3,4]\n",
    "    \n",
    "    (y_pred_dec_tree, \n",
    "    conf_mat_dec_tree, \n",
    "    dec_tree_scores, \n",
    "    dec_tree_scores_list) = crossvalidation(dec_tree_best,\n",
    "                                            examples,\n",
    "                                            target,\n",
    "                                            a)\n",
    "    if tree_vis:\n",
    "        dot_data = tree.export_graphviz(dec_tree_best, \n",
    "                                        feature_names = fnames,\n",
    "                                        out_file = None,\n",
    "                                        filled = True, \n",
    "                                        rounded = True,\n",
    "                                        special_characters = True)\n",
    "\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_binary, target_binary, True, True, fnames_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the decision tree model is highly complex. This is an expected result, as one hot encoding creates many binary features, which lead to large decision trees that split in many different ways. The best feature according to this model was `Age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Models - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a pipeline for training and testing linear SVM\n",
    "# on binary or multiclass analysis\n",
    "# args:\n",
    "# binary = (boolean) whether the analysis is binary or not\n",
    "\n",
    "def lsvm(eaxmples, target, binary):\n",
    "    \n",
    "    # Initialising the estimator\n",
    "    lsvm = LinearSVC(max_iter = 15000, dual = False) # max_iter=1000 (default) didn't converge: dual = False recommended for large datasets\n",
    "    \n",
    "    # Grid search (hyperparameter tuning) and k-fold cross-validation fitting/scoring\n",
    "    if(binary):\n",
    "        lsvm_p = {'penalty': ['l1','l2']}\n",
    "    else:\n",
    "        lsvm_p =  {'C':[0.0001,0.001,0.01,0.1,1,10,100],\n",
    "                'class_weight':[None,'balanced'],\n",
    "                'max_iter':[10000],\n",
    "                'penalty':['l1','l2']}\n",
    "        \n",
    "    lsvm_grid = GridSearchCV(lsvm, \n",
    "                             lsvm_p, \n",
    "                             scoring='f1_macro',\n",
    "                             cv=5,\n",
    "                             verbose=10,\n",
    "                             n_jobs = 1) # creates all 2 versions of the decision tree model\n",
    "    \n",
    "    lsvm_grid.fit(examples,target)\n",
    "    \n",
    "    # Picking and revalidating the best estimator\n",
    "    lsvm_best = lsvm_grid.best_estimator_ # assigning the parameters to the linear SVM estimator\n",
    "    print('Best estimator:\\n\\n{}'.format(lsvm_best))\n",
    "    \n",
    "    # Print scores\n",
    "    if binary:\n",
    "        a = [0,1]\n",
    "    else:\n",
    "        a = [0,1,2,3,4]\n",
    "    \n",
    "    (y_pred_lsvm, \n",
    "     conf_mat_lsvm, \n",
    "     lsvm_scores, \n",
    "     lsvm_scores_list) = crossvalidation(lsvm_best,\n",
    "                                        examples,\n",
    "                                        target,\n",
    "                                        a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm(examples_binary, target_binary, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model's performance may have benefitted from one hot encoding, seeing as though most examples can only occupy two possible coordinates in each of their spacial dimensions (features) and that could ease linear separability.\n",
    "\n",
    "The imbalance remains a problem to address, given poor accuracy in prediction of `Adoption=0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall conclusions\n",
    "\n",
    "Assuming the models are in fact learning correctly, the most evident problem in the dataset is the imbalance. However, it's also *very likely the models are not learning appropriately at all*.\n",
    "\n",
    "Given that we have approximately a 2.6 : 1 ratio of `Adoption=1` to `Adoption=0`, even if the models were always guessing `Adoption=1`, they would still be 2.6 times more likely to guess right and inflate accuracy results, meaning the model is ignoring the minority class and getting good scores based on the poorly prepared dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.2 Predicting AdoptionSpeed (multiclass classification task) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_bench_multi, target_bench_multi, fnames_bench_multi, tname_bench_multi = separate_split(df_processed1_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Adoption=0 examples in the dataset: {}\".format(np.count_nonzero(target_bench_multi == 0)))\n",
    "print(\"Number of Adoption=1 examples in the dataset: {}\".format(np.count_nonzero(target_bench_multi == 1)))\n",
    "print(\"Number of Adoption=2 examples in the dataset: {}\".format(np.count_nonzero(target_bench_multi == 2)))\n",
    "print(\"Number of Adoption=3 examples in the dataset: {}\".format(np.count_nonzero(target_bench_multi == 3)))\n",
    "print(\"Number of Adoption=4 examples in the dataset: {}\".format(np.count_nonzero(target_bench_multi == 4)))\n",
    "print(\"Ratio of least representative class to most representative class in the dataset: {}\".format((np.count_nonzero(target_bench_multi == 0))/(np.count_nonzero(target_bench_multi == 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance-based Models - K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(examples_bench_multi,target_bench_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the imbalanced dataset and using GridSearchCV to find the best possible hyperparameters parameters for the K-Nearest Neighbours algorithm, it was found that 4 neighbours and a minkowski distance of p=1 (Manhattan) were the best possible hyperparameters for an f1_macro scoring metric.\n",
    "The results on the minority class are very poor not only regarding precision but also the ability to identify correctly the relevant examples (recall). \n",
    "\n",
    "The class imbalance seems to be having a great influence on the model's ability to lear the minority class. The most representative classes show a somewhat increasing performance with increasing number of learning examples and a similar performance regarding precision and recall.\n",
    "\n",
    "The most representative class (adoptionspeed=4) is the one in which this model shows better performance both regarding precision and recall.\n",
    "\n",
    "The overall performance of this model is compromised by the low performance on the minority class which hints that balancing the dataset will probably provide better results. \n",
    "\n",
    "It also seems clear that the model is overfitting the dataset since training scores are generally 3 times higher than the test set scores for the same model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probabilistic Models - Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli(examples_bench_multi,target_bench_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fold the performance on the training set is similar to the one on the test set and around 0.36/0.37. This clearly suggests the model is underfitting the data. \n",
    "\n",
    "Performance on the minority class is very poor even when compared with the performance of the model on the other classes, with few examples being correctly classified. \n",
    "\n",
    "The most representative class (adoptionspeed=4) is the one in which this model shows better performance both regarding precision and recall.\n",
    "\n",
    "The poor performance on the minority class is also degrading the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tree Models - Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_bench_multi, target_bench_multi, False, True, fnames_bench_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the imbalanced dataset and using GridSearchCV to find the best possible hyperparameters for the Decision Tree, it was found that a minimum number of samples required for a split of 2, a minimum number of samples required to be at a leaf node of 1 and a entropy measure, to be optimal regarding a f1_macro scoring metric.\n",
    "\n",
    "The most representative class (adoptionspeed=4) is the one in which this model shows better performance both regarding precision and recall.\n",
    "\n",
    "The overall performance of this model is compromised by the low performance on the minority class which hints that balancing the dataset will provide better results. \n",
    "\n",
    "It also seems clear that the model is overfitting the dataset since training scores are generally 3 times higher than the test set scores for the same model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Models  - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm(examples_bench_multi,target_bench_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the imbalanced dataset and using GridSearchCV to find the best possible hyperparameters for the Linear Support Vector Machine, it was found that a regularization parameter (C) of 0.1 and a l2 penalty norm were optimal, despite de inability of the algoritm to converge, despite the high number of iterations 10000. This might suggest that the data is not entirely linearly separable and that using a kernell algoritm would increase performance, or at least converge towards a solution.\n",
    "\n",
    "The most representative class (adoptionspeed=4) is the one in which this model shows better performance both regarding precision and recall.\n",
    "\n",
    "The overall performance of this model is compromised by the low performance on the minority class which hints that balancing the dataset will provide better results. \n",
    "\n",
    "Its also seems clear that the model is underfitting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Benchmark conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Decision trees and K-Nearest Neighbours provided almost perfect results on the training sets but performed considerably worst on the test set Both this models seem to be overfitting the training examples and failing to generalize over unseen examples. On the other hand, both Linear Support Vector Machines and Bernoulli Naive Bayes show considerable underfitting of the data with training scores below 0.40. \n",
    "\n",
    "Regarding individiual class performances none of the models showed great ability to provide the minority class (adoptionspeed=0) which underlines the need of oversampling the dataset to provide the algorithms with stronger evidence of that class. \n",
    "\n",
    "From all the tested approaches, the Bernoulli Naive Bayes model was the one that showcased better results in both AdoptionSpeed=1 and Linear Support Vector Machines the best for AdoptionSpeed=4 classes with higher precision and recall scores. On the other hand the K-Nearest Neighbours model performed better in both AdoptionSpeed=2 and AdoptionSpeed=3.\n",
    "\n",
    "All the models showcase similar low overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Predicting Adoption (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dataset `df_processed2_b_balanced_encoded` (binary target, balanced examples and encoded features), we will run the same algorithms as in the previous section, **1.2.1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = separate_split(df_processed2_b_balanced_encoded,True)\n",
    "examples_binary, target_binary, fnames_binary, tname_binary = separate_split(df_processed2_b_balanced_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_binary == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_binary == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_binary == 1))/(np.count_nonzero(target_binary == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance-based Models - K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(examples_binary, target_binary,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search algorithm has returned a different set of hyperparameters, with `n_neighbors` reduced to `2`. This might be related to the oversampling of the minority class. With rarer occurences of the minority class, the benchmark model might have had to increase the number of neighbours to increase the odds of finding `Adoption=0` and therefore improve prediction. The random oversampling ensures a greater number of negative cases in the overall landscape, driving the number of neighbours to decrease. The distance measure is now Euclidian (`p = 2`), and `weights` takes distance into consideration (possibly because with only two neighbours, using distance is more effective for breaking ties which become more often).\n",
    "\n",
    "The results have improved significantly from the benchmark tests. Both training and test accuracies have improved, as well as prediction of both classes. The most significant increase was for prediction of `Adoption=0`, for which prediction accuracy almost doubled, once again suggesting oversampling the dataset was a good choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probabilistic Models - Bernoulli Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli(examples_binary, target_binary,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy was reduced considerably (from ~72% to ~65%). This can be seen in the noticeable decrease in performance for prediction of `Adoption=1`. However, as a positive point, this version of the model is significantly better at predicting `Adoption=0` (an F1 score increase of 0.19, from 0.45 to 0.64). It is also much more even in the prediction success in both classes, whereas the previous one showed a significant discrepancy in prediction of the minority class. We can see that oversampling was a good option for this dataset to mitigate minority class problems.\n",
    "\n",
    "Perhaps a probabilistic model is not suited to this dataset, as the exploratory data analysis revealed very few correlations between features (and, therefore, pet profiles) and odds of adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tree Models - Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_binary,target_binary,True,True,fnames_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Linear Models - Support Vector Machines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm(examples_binary, target_binary,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 Predicting Adoption Speed (Multiclass classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dataset `df_processed2_m_balanced_encoded` (multiclass target, balanced examples and encoded features), we will run the same algorithms as in the previous section, **1.2.1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_multi, target_multi, fnames_multi, tname_multi = separate_split(df_processed2_m_balanced_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Adoption=0 examples in the dataset: {}\".format(np.count_nonzero(target_multi == 0)))\n",
    "print(\"Number of Adoption=1 examples in the dataset: {}\".format(np.count_nonzero(target_multi == 1)))\n",
    "print(\"Number of Adoption=2 examples in the dataset: {}\".format(np.count_nonzero(target_multi == 2)))\n",
    "print(\"Number of Adoption=3 examples in the dataset: {}\".format(np.count_nonzero(target_multi == 3)))\n",
    "print(\"Number of Adoption=4 examples in the dataset: {}\".format(np.count_nonzero(target_multi == 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Distance-based Models - K-Nearest Neighbours***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(examples_multi, target_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Compared to the results for the K-Neighbours used on the benchmark section for the multiclass task, and as expected, the results on the former minority class (AdoptionSpeed = 0) greatly improved with an almost perfect score in that particular class. \n",
    "\n",
    "However, this results may be somewhat a consequence of the oversampling made (all the examples on the adoptionspeed = 0  class where theoretically replicated 10x times) which granted the existence of many of the same examples closer together and in both the training and test sets. This is confirmed by the reduction from 4 to 2, on the number of neighbours considered by gridsearchcv to be optimal.\n",
    "\n",
    "Despite the overall improvement the model still seems to be slightly overfitting the data from the other classes as it fails to properly generalise. This lack of generelization affects the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Probabilistic Models - Naïve Bayes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli(examples_multi, target_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Naive Bayes on the balanced dataset show slightly worse overall results (0.36 on the imbalanced set vs 0.34 on the balanced one).\n",
    "\n",
    "The performance on the other classes aside from AdoptionSpeed=0 and AdoptionSpeed=3 an has decreased which might indicate that either this model is not the most approriate for this balanced task or that the chosen approach was not the most suitable to take the best out of the model.\n",
    "\n",
    "Other relevant information is that the model still underfits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Tree Models - Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_multi,target_multi,False,False,fnames_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Compared to the results for the Decision Tree used on the benchmark section for the multiclass task, and as somewhat expected, the performance across different classes improved specially adoptionspeed=0.\n",
    "\n",
    "Despite the overall improvement the model still seems to be overfitting the data from the all classes besides adoptionspeed=0 as it fails to properly generalise.\n",
    "\n",
    "This model shows similar overall results as the K-Nearest Neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Linear Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm(examples_multi,target_multi,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear Support Vector Machines on the balanced dataset shows the same global performance (0.36) but worse performance in all classes besides AdoptionSpeed=0, which greatly improved, and AdoptionSpeed=3, which slightly improved. This might indicate that either this model is not the most approriate for this balanced task or that the chosen approach was not the most suitable to take the best out of the model.\n",
    "\n",
    "Other relevant information is that the model still underfits the training data and that convergence wasn't achieved despite the high number of interations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rule Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Multi class classification - Conclusions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.4 Predicting Adoption/Adoption Speed for dogs\n",
    "\n",
    "For this pet-type-specific analysis we will only test the classification model that had the best performance on the previous tasks, namely the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b_dogs, X_test_b_dogs, y_train_b_dogs, y_test_b_dogs = separate_split(df_processed2_b_balanced_dogs_encoded,True)\n",
    "examples_b_dogs, target_b_dogs, fnames_b_dogs, tname_b_dogs = separate_split(df_processed2_b_balanced_dogs_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_b_dogs == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_b_dogs == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_b_dogs == 1))/(np.count_nonzero(target_b_dogs == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tree Models - Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_b_dogs,target_b_dogs,True,False,fnames_b_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the results for the dogs' dataset were very similar to the dataset containing both types of pets, in terms of precision, recall, accuracy and F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m_dogs, X_test_m_dogs, y_train_m_dogs, y_test_m_dogs = separate_split(df_processed2_m_balanced_dogs_encoded,True)\n",
    "examples_m_dogs, target_m_dogs, fnames_m_dogs, tname_m_dogs = separate_split(df_processed2_m_balanced_dogs_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_m_dogs == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_m_dogs == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_m_dogs == 1))/(np.count_nonzero(target_m_dogs == 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_m_dogs, target_m_dogs,False,False,fnames_m_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.5 Predicting Adoption/Adoption Speed for cats\n",
    "For this pet-type-specific analysis we will only test the classification model that had the best performance on the previous tasks, namely the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b_cats, X_test_b_cats, y_train_b_cats, y_test_b_cats = separate_split(df_processed2_b_balanced_cats_encoded,True)\n",
    "examples_b_cats, target_b_cats, fnames_b_cats, tname_b_cats = separate_split(df_processed2_b_balanced_cats_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_b_cats == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_b_cats == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_b_cats == 1))/(np.count_nonzero(target_b_cats == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tree Models - Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_b_cats,target_b_cats,True,False,fnames_b_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m_cats, X_test_m_cats, y_train_m_cats, y_test_m_cats = separate_split(df_processed2_m_balanced_cats_encoded,True)\n",
    "examples_m_cats, target_m_cats, fnames_m_cats, tname_m_cats = separate_split(df_processed2_m_balanced_cats_encoded,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of positives cases in the dataset is: {}\".format(np.count_nonzero(target_m_cats == 1)))\n",
    "print(\"Number of negative cases in the dataset is: {}\".format(np.count_nonzero(target_m_cats == 0)))\n",
    "print(\"Ratio of positive to negative cases in the dataset: {}\".format((np.count_nonzero(target_m_cats == 1))/(np.count_nonzero(target_m_cats == 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(examples_m_cats, target_m_cats,False,False,fnames_m_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (Unsupervised Learning) - Charactering Adopted Pets and Adoption Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize pets that were actually adopted and their adoption speed**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Adoption/AdoptionSpeed**.\n",
    "* **Clustering algorithms to find similar groups of pets**. Is it possible to find groups of pets with the same/similar adoption speed.\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preprocessing Data for Association Rule Mining\n",
    "\n",
    "In order to perform Association Rule Mining, we need to transform our dataset in such a way that each line is a transaction, consisting of a list of features and their respective value.\n",
    "\n",
    "E.g. transaction1 = [ `hasName` = 1, `type` = 2, `Age` = 35, (...) ]\n",
    "\n",
    "We will use the balanced datasets for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function encodes the previous dataset form into a Association Rule Mining friendly dataset\n",
    "# which is a binary database\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "def t_encoder(df):\n",
    "    transactions=[] #list of transactions\n",
    "    t=[] #list for each transaction\n",
    "    s='' #string for building each item in the transaction\n",
    "\n",
    "    rows = len(df.index) # nr of rows\n",
    "\n",
    "    for i in range(rows):\n",
    "        transactions.append(t)\n",
    "        t=[]\n",
    "        for c in list(df):\n",
    "            s = c + \"=\" + str(df[c][i]) # build item strings\n",
    "            t.append(s) # attach each item to the respective transaction\n",
    "\n",
    "    transactions.pop(0) #eliminate first empty element\n",
    "\n",
    "    #Compute binary database\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    binary_database = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    return binary_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_binary = t_encoder(df_processed2_b_balanced)\n",
    "t_multiclass = t_encoder(df_processed2_m_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Finding Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in exploring the associations between features and the target class, we will filter the dataset in order to obtain rules having `Adoption` or `AdoptionSpeed` as a consequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(transactions, min_support, metric, min_treshold, binary):\n",
    "    #Compute itemsets with min_support indicated\n",
    "    frequent_itemsets = apriori(transactions, min_support=min_support,use_colnames=True)\n",
    "    \n",
    "    # Generate association rules with confidence indicated\n",
    "    rules = association_rules(frequent_itemsets, metric=metric, min_threshold=min_treshold)  \n",
    "    \n",
    "    # Transform consequents to string in order to filter\n",
    "    rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: ' '.join(list(x))).astype(\"unicode\")\n",
    "    \n",
    "    #Find consequents containing \"Adoption\" or \"AdoptionSpeed\"\n",
    "    count=-1\n",
    "    indexes=[]\n",
    "    \n",
    "    if binary:\n",
    "        for i in rules[\"consequents\"]:\n",
    "            count+=1\n",
    "            for j in i.split(' '):\n",
    "                if j==\"Adoption=1.0\" or j==\"Adoption=0.0\":\n",
    "                    indexes.append(count) # save indexes from rows containing Adoption as consequent\n",
    "    else:\n",
    "        for i in rules[\"consequents\"]:\n",
    "            count+=1\n",
    "            for j in i.split(' '):\n",
    "                if j==\"AdoptionSpeed=0.0\" or j==\"AdoptionSpeed=1.0\" or j==\"AdoptionSpeed=2.0\" or j==\"AdoptionSpeed=3.0\" or j==\"AdoptionSpeed=4.0\":\n",
    "                    indexes.append(count) # save indexes from rows containing AdoptionSpeed as consequent\n",
    "\n",
    "    new_rules = pd.DataFrame(columns=rules.columns)\n",
    "    \n",
    "    for i in indexes: # create new dataset containing the rules of interest only \n",
    "        new_rules = new_rules.append(rules.iloc[i])\n",
    "    \n",
    "    return frequent_itemsets, rules, new_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification\n",
    "\n",
    "* talk about lift and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets_b, rules_b, new_rules_b = rules(t_binary,0.45,\"lift\",1.0,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total we have  240  frequent itemsets.\n",
      "In total we have found  1102  association rules.\n"
     ]
    }
   ],
   "source": [
    "print(\"In total we have \", frequent_itemsets_b.shape[0], \" frequent itemsets.\")\n",
    "print(\"In total we have found \", rules_b.shape[0], \" association rules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(hasVideo=0.0)</td>\n",
       "      <td>Adoption=0.0</td>\n",
       "      <td>0.964661</td>\n",
       "      <td>0.499977</td>\n",
       "      <td>0.485619</td>\n",
       "      <td>0.503409</td>\n",
       "      <td>1.006864</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>1.006911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Health=1.0)</td>\n",
       "      <td>Adoption=1.0</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.484739</td>\n",
       "      <td>0.503706</td>\n",
       "      <td>1.007365</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>1.007420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>(hasVideo=0.0)</td>\n",
       "      <td>Health=1.0 Adoption=0.0</td>\n",
       "      <td>0.964661</td>\n",
       "      <td>0.477606</td>\n",
       "      <td>0.463943</td>\n",
       "      <td>0.480939</td>\n",
       "      <td>1.006978</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>1.006421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>(Health=1.0, hasVideo=0.0)</td>\n",
       "      <td>Adoption=1.0</td>\n",
       "      <td>0.928257</td>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.464314</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>1.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>(Health=1.0)</td>\n",
       "      <td>Adoption=1.0 hasVideo=0.0</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.464314</td>\n",
       "      <td>0.482481</td>\n",
       "      <td>1.007179</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>1.006646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   antecedents                consequents  antecedent support  \\\n",
       "1               (hasVideo=0.0)               Adoption=0.0            0.964661   \n",
       "3                 (Health=1.0)               Adoption=1.0            0.962345   \n",
       "79              (hasVideo=0.0)    Health=1.0 Adoption=0.0            0.964661   \n",
       "81  (Health=1.0, hasVideo=0.0)               Adoption=1.0            0.928257   \n",
       "83                (Health=1.0)  Adoption=1.0 hasVideo=0.0            0.962345   \n",
       "\n",
       "    consequent support   support  confidence      lift  leverage  conviction  \n",
       "1             0.499977  0.485619    0.503409  1.006864  0.003311    1.006911  \n",
       "3             0.500023  0.484739    0.503706  1.007365  0.003544    1.007420  \n",
       "79            0.477606  0.463943    0.480939  1.006978  0.003215    1.006421  \n",
       "81            0.500023  0.464314    0.500200  1.000353  0.000164    1.000353  \n",
       "83            0.479042  0.464314    0.482481  1.007179  0.003310    1.006646  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rules_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets_m, rules_m, new_rules_m = rules(t_multiclass,0.45,\"lift\",1.0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total we have found  251  frequent itemsets.\n",
      "In total we have found  1282  association rules.\n"
     ]
    }
   ],
   "source": [
    "print(\"In total we have found \", frequent_itemsets_m.shape[0], \" frequent itemsets.\")\n",
    "print(\"In total we have found \", rules_m.shape[0], \" association rules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>(Breed2=0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.482749</td>\n",
       "      <td>(Color1=1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699581</td>\n",
       "      <td>(Color3=0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.548132</td>\n",
       "      <td>(Dewormed=1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.850886</td>\n",
       "      <td>(Free=0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.530833</td>\n",
       "      <td>(Free=0.0, hasName=1.0, hasVideo=0.0, Health=1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.471550</td>\n",
       "      <td>(Free=0.0, hasName=1.0, hasVideo=0.0, Maturity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.544605</td>\n",
       "      <td>(Free=0.0, hasName=1.0, hasVideo=0.0, Quantity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.474171</td>\n",
       "      <td>(Free=0.0, Sterilized=2.0, hasName=1.0, hasVid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>(hasName=1.0, hasVideo=0.0, Quantity=1.0, Heal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                                           itemsets\n",
       "0    0.697579                                       (Breed2=0.0)\n",
       "1    0.482749                                       (Color1=1.0)\n",
       "2    0.699581                                       (Color3=0.0)\n",
       "3    0.548132                                     (Dewormed=1.0)\n",
       "4    0.850886                                         (Free=0.0)\n",
       "..        ...                                                ...\n",
       "246  0.530833  (Free=0.0, hasName=1.0, hasVideo=0.0, Health=1...\n",
       "247  0.471550  (Free=0.0, hasName=1.0, hasVideo=0.0, Maturity...\n",
       "248  0.544605  (Free=0.0, hasName=1.0, hasVideo=0.0, Quantity...\n",
       "249  0.474171  (Free=0.0, Sterilized=2.0, hasName=1.0, hasVid...\n",
       "250  0.510913  (hasName=1.0, hasVideo=0.0, Quantity=1.0, Heal...\n",
       "\n",
       "[251 rows x 2 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Color3=0.0)</td>\n",
       "      <td>Breed2=0.0</td>\n",
       "      <td>0.699581</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.496759</td>\n",
       "      <td>0.710082</td>\n",
       "      <td>1.017923</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>1.043125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(Breed2=0.0)</td>\n",
       "      <td>Color3=0.0</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.699581</td>\n",
       "      <td>0.496759</td>\n",
       "      <td>0.712119</td>\n",
       "      <td>1.017923</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>1.043555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(Breed2=0.0)</td>\n",
       "      <td>Free=0.0</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.850886</td>\n",
       "      <td>0.601887</td>\n",
       "      <td>0.862823</td>\n",
       "      <td>1.014028</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>1.087014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Free=0.0)</td>\n",
       "      <td>Breed2=0.0</td>\n",
       "      <td>0.850886</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.601887</td>\n",
       "      <td>0.707365</td>\n",
       "      <td>1.014028</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>1.033440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(Quantity=1.0)</td>\n",
       "      <td>Breed2=0.0</td>\n",
       "      <td>0.777259</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.554947</td>\n",
       "      <td>0.713979</td>\n",
       "      <td>1.023510</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>1.057339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1277</td>\n",
       "      <td>(Health=1.0, FrequentRescuer=1.0)</td>\n",
       "      <td>hasName=1.0 Quantity=1.0 hasVideo=0.0</td>\n",
       "      <td>0.719596</td>\n",
       "      <td>0.682282</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.040626</td>\n",
       "      <td>0.019946</td>\n",
       "      <td>1.095580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1278</td>\n",
       "      <td>(hasName=1.0)</td>\n",
       "      <td>Quantity=1.0 Health=1.0 hasVideo=0.0 FrequentR...</td>\n",
       "      <td>0.893872</td>\n",
       "      <td>0.551754</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>0.571573</td>\n",
       "      <td>1.035921</td>\n",
       "      <td>0.017716</td>\n",
       "      <td>1.046261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1279</td>\n",
       "      <td>(Quantity=1.0)</td>\n",
       "      <td>hasName=1.0 Health=1.0 hasVideo=0.0 FrequentRe...</td>\n",
       "      <td>0.777259</td>\n",
       "      <td>0.630671</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>0.657327</td>\n",
       "      <td>1.042266</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>1.077788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>(Health=1.0)</td>\n",
       "      <td>hasName=1.0 Quantity=1.0 hasVideo=0.0 Frequent...</td>\n",
       "      <td>0.964211</td>\n",
       "      <td>0.526735</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>0.529877</td>\n",
       "      <td>1.005966</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>1.006684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>(FrequentRescuer=1.0)</td>\n",
       "      <td>hasName=1.0 Quantity=1.0 Health=1.0 hasVideo=0.0</td>\n",
       "      <td>0.740850</td>\n",
       "      <td>0.656214</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>0.689631</td>\n",
       "      <td>1.050923</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>1.107667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            antecedents  \\\n",
       "0                          (Color3=0.0)   \n",
       "1                          (Breed2=0.0)   \n",
       "2                          (Breed2=0.0)   \n",
       "3                            (Free=0.0)   \n",
       "4                        (Quantity=1.0)   \n",
       "...                                 ...   \n",
       "1277  (Health=1.0, FrequentRescuer=1.0)   \n",
       "1278                      (hasName=1.0)   \n",
       "1279                     (Quantity=1.0)   \n",
       "1280                       (Health=1.0)   \n",
       "1281              (FrequentRescuer=1.0)   \n",
       "\n",
       "                                            consequents  antecedent support  \\\n",
       "0                                            Breed2=0.0            0.699581   \n",
       "1                                            Color3=0.0            0.697579   \n",
       "2                                              Free=0.0            0.697579   \n",
       "3                                            Breed2=0.0            0.850886   \n",
       "4                                            Breed2=0.0            0.777259   \n",
       "...                                                 ...                 ...   \n",
       "1277              hasName=1.0 Quantity=1.0 hasVideo=0.0            0.719596   \n",
       "1278  Quantity=1.0 Health=1.0 hasVideo=0.0 FrequentR...            0.893872   \n",
       "1279  hasName=1.0 Health=1.0 hasVideo=0.0 FrequentRe...            0.777259   \n",
       "1280  hasName=1.0 Quantity=1.0 hasVideo=0.0 Frequent...            0.964211   \n",
       "1281   hasName=1.0 Quantity=1.0 Health=1.0 hasVideo=0.0            0.740850   \n",
       "\n",
       "      consequent support   support  confidence      lift  leverage  conviction  \n",
       "0               0.697579  0.496759    0.710082  1.017923  0.008747    1.043125  \n",
       "1               0.699581  0.496759    0.712119  1.017923  0.008747    1.043555  \n",
       "2               0.850886  0.601887    0.862823  1.014028  0.008327    1.087014  \n",
       "3               0.697579  0.601887    0.707365  1.014028  0.008327    1.033440  \n",
       "4               0.697579  0.554947    0.713979  1.023510  0.012747    1.057339  \n",
       "...                  ...       ...         ...       ...       ...         ...  \n",
       "1277            0.682282  0.510913    0.710000  1.040626  0.019946    1.095580  \n",
       "1278            0.551754  0.510913    0.571573  1.035921  0.017716    1.046261  \n",
       "1279            0.630671  0.510913    0.657327  1.042266  0.020718    1.077788  \n",
       "1280            0.526735  0.510913    0.529877  1.005966  0.003030    1.006684  \n",
       "1281            0.656214  0.510913    0.689631  1.050923  0.024757    1.107667  \n",
       "\n",
       "[1282 rows x 9 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\n",
       "Index: []"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rules_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Preprocessing Data for Clustering\n",
    "\n",
    "For this task we will use the same processed dataset as we used for the Binary and Multiclass Classification tasks, df_processed2_b_balanced_encoded and df_processed2_m_balanced_encoded. k-Means uses distance computation as a metric in its algorithm, and hence cannot handle categorical variable directly. That is the reason why we use the encoded datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATASET\n",
    "nc_b = df_processed2_b_balanced_encoded.shape[1] # number of columns\n",
    "table_X_b = df_processed2_b_balanced_encoded.iloc[:, 0:nc_b-1] # get features ignoring AdoptionSpeed\n",
    "table_y_b = df_processed2_b_balanced_encoded.iloc[:, nc_b-1] # get class (last columns) \n",
    "\n",
    "nc_m = df_processed2_m_balanced_encoded.shape[1] # number of columns\n",
    "table_X_m = df_processed2_m_balanced_encoded.iloc[:, 0:nc_m-1] # get features ignoring AdoptionSpeed\n",
    "table_y_m = df_processed2_m_balanced_encoded.iloc[:, nc_m-1] # get class (last columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dimension has the same weight in the k-means algorithm, but since our data has dimensions in different scales (some are binary, ranging from 1 to 0 while others are continuous, ranging from 0 to 250 - `Age`) we will proceed to standardizing the data, in order to avoid distortion on the relative near-ness of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARDIZING THE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled_b = scaler.fit_transform(table_X_b)\n",
    "data_scaled_m = scaler.fit_transform(table_X_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find out if it's possible to find groups of pets with the same/similar adoption speed, we will look at the k=2 and k=5 clusters obtained from k-Means and determine whether they coincide with the AdoptionSpeed groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_b = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans_m = KMeans(n_clusters=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-means\n",
    "kmeans_b = kmeans_b.fit(data_scaled_b)\n",
    "kmeans_m = kmeans_m.fit(data_scaled_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function produces a confusion matrix with the percentual membership\n",
    "# (of the points in each cluster) to a given feature\n",
    "\n",
    "def df_confusion(cluster, table_a):\n",
    "    df = pd.DataFrame(set(table_a))\n",
    "    df = df.set_index(0)\n",
    "\n",
    "    for i in set(cluster): df[i] = 0 \n",
    "    i=0\n",
    "    while i < len(cluster):\n",
    "        df.loc[table_a[i], cluster[i]]+=1\n",
    "        i += 1\n",
    "    for i in set(df.columns): \n",
    "        Total = df[i].sum()\n",
    "        for j in set(df.index):\n",
    "            df.loc[j, i] = (df.loc[j, i] / Total)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Binary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare membership for binary dataset\n",
    "df1 = df_confusion(kmeans_b.labels_, table_y_b)\n",
    "ax = sns.heatmap(df1, annot=True)\n",
    "ax.set_xlabel('kmeans label')\n",
    "ax.set_ylabel('true label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Multiclass analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare membership for multiclass dataset\n",
    "df2 = df_confusion(kmeans_m.labels_, table_y_m)\n",
    "ax = sns.heatmap(df2, annot=True)\n",
    "ax.set_xlabel('kmeans label')\n",
    "ax.set_ylabel('true label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In respect to the Binary analysis, we can see in the confusion matrix that the negative examples are evenly distributed through both clusters obtained from k-means, and the same happens for the positive examples. Thus, we conclude that the groups obtained from k-means do not coincide with the groups from the target class. \n",
    "\n",
    "In the Multiclass analysis, the confusion matrix indicates that none of the clusters hold more than 30% of examples from any AdoptionSpeed class, thus we conclude that there is no evident agreement between the predicted clusters and the real target groups.\n",
    "\n",
    "These poor results can be explained due to the complexity and high dimensionality of the dataset, because when we have so many features (378) distance interpretation isn’t so obvious. An additional step employing Principal Component Analysis to reduce dimensionality might've helped get more productive results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
